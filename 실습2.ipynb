{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b_B090vzAttt",
        "UigUfXnkAsC8",
        "LuwX4qiZA8p9",
        "0G2OAxPzruCm",
        "24sACTIQ5OiE",
        "o_bqTrZKC4T7",
        "nrcA9sykExJ5",
        "xAFhXskHS-iR"
      ],
      "authorship_tag": "ABX9TyPXdWmW84T8Rcir61uC5HJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sominshim/DL_beginner/blob/main/%EC%8B%A4%EC%8A%B52.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_1_2_linear_regression.py"
      ],
      "metadata": {
        "id": "b_B090vzAttt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 공부한 시간\n",
        "x = [[1],\n",
        "     [2],\n",
        "     [3]]\n",
        "# 성적\n",
        "y = [[1],\n",
        "     [2],\n",
        "     [3]]\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(0.1),\n",
        "              loss=tf.keras.losses.mse)\n",
        "\n",
        "model.fit(x, y, epochs=10)\n",
        "\n",
        "# 퀴즈\n",
        "# x가 5와 7일 때의 결과는 얼마입니까?\n",
        "print(model.predict(x))\n",
        "print(model.predict([[1],\n",
        "                     [2],\n",
        "                     [3]]))\n",
        "print(model.predict([[5],\n",
        "                     [7]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI9pz5dO_ZtM",
        "outputId": "33244d27-a4db-469d-b251-0a7fdefe2268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 28.8449\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4579\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1134\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1041\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0992\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0944\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0900\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0857\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0816\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0777\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "[[1.4023898]\n",
            " [2.0863523]\n",
            " [2.7703152]]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[1.4023898]\n",
            " [2.0863523]\n",
            " [2.7703152]]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[4.1382403]\n",
            " [5.5061655]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_1_3_multiple_regression.py"
      ],
      "metadata": {
        "id": "UigUfXnkAsC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DL_1_3_multiple_regression.py\n",
        "import tensorflow as tf\n",
        "\n",
        "# 공부시간, 출석일수\n",
        "x = [[1, 2],\n",
        "     [2, 1],\n",
        "     [4, 5],\n",
        "     [5, 4],\n",
        "     [8, 9],\n",
        "     [9, 8]]\n",
        "y = [[3],\n",
        "     [3],\n",
        "     [9],\n",
        "     [9],\n",
        "     [17],\n",
        "     [17]]\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=[2]))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NwkQZSgAqlM",
        "outputId": "fb07b807-3329-497d-e866-a986978287d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
        "              loss=tf.keras.losses.mse)\n",
        "\n",
        "model.fit(x, y, epochs=100, verbose=2)\n",
        "\n",
        "# 퀴즈\n",
        "# 5시간 공부하고 2번 출석한 학생과\n",
        "# 3시간 공부하고 6번 출석한 학생의 성적을 구하세요\n",
        "print(model.predict([[5, 2],\n",
        "                             [3, 6]], verbose=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "3vS93ldTBQr1",
        "outputId": "d423327b-0272-4489-cc6c-e8b2bbeb4107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-f16b04f3312a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    matrics='acc')\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_2_1_trees.py"
      ],
      "metadata": {
        "id": "LuwX4qiZA8p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/trees.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YosalUCeA7w9",
        "outputId": "49413f7f-7b0d-4e80-f3f6-6e6bf28b4f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Girth  Height  Volume\n",
              "0           1    8.3      70    10.3\n",
              "1           2    8.6      65    10.3\n",
              "2           3    8.8      63    10.2\n",
              "3           4   10.5      72    16.4\n",
              "4           5   10.7      81    18.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d12ee049-1562-4a4c-98e5-c9c9ca4f3932\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Girth</th>\n",
              "      <th>Height</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>8.3</td>\n",
              "      <td>70</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>8.6</td>\n",
              "      <td>65</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>8.8</td>\n",
              "      <td>63</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>10.5</td>\n",
              "      <td>72</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10.7</td>\n",
              "      <td>81</td>\n",
              "      <td>18.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d12ee049-1562-4a4c-98e5-c9c9ca4f3932')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d12ee049-1562-4a4c-98e5-c9c9ca4f3932 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d12ee049-1562-4a4c-98e5-c9c9ca4f3932');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 잘 불러오는 방법\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/trees.csv',\n",
        "                            index_col=0)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PVYbxzv_B35g",
        "outputId": "37d3b78b-6527-4c62-a04b-249549295a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Girth  Height  Volume\n",
              "1    8.3      70    10.3\n",
              "2    8.6      65    10.3\n",
              "3    8.8      63    10.2\n",
              "4   10.5      72    16.4\n",
              "5   10.7      81    18.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17345dae-f39c-440f-a54b-88e63b4e050b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Girth</th>\n",
              "      <th>Height</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3</td>\n",
              "      <td>70</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.6</td>\n",
              "      <td>65</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.8</td>\n",
              "      <td>63</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.5</td>\n",
              "      <td>72</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10.7</td>\n",
              "      <td>81</td>\n",
              "      <td>18.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17345dae-f39c-440f-a54b-88e63b4e050b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17345dae-f39c-440f-a54b-88e63b4e050b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17345dae-f39c-440f-a54b-88e63b4e050b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 잘 불러오는 방법\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/trees.csv',\n",
        "                            index_col=0)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A7TOqKOQB70A",
        "outputId": "9e548685-ca01-454e-e6fa-d8796ff983e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Girth  Height  Volume\n",
              "1    8.3      70    10.3\n",
              "2    8.6      65    10.3\n",
              "3    8.8      63    10.2\n",
              "4   10.5      72    16.4\n",
              "5   10.7      81    18.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cc7ebc8-f305-428e-b15e-bdbea2bd156a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Girth</th>\n",
              "      <th>Height</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3</td>\n",
              "      <td>70</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.6</td>\n",
              "      <td>65</td>\n",
              "      <td>10.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.8</td>\n",
              "      <td>63</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.5</td>\n",
              "      <td>72</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10.7</td>\n",
              "      <td>81</td>\n",
              "      <td>18.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cc7ebc8-f305-428e-b15e-bdbea2bd156a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cc7ebc8-f305-428e-b15e-bdbea2bd156a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cc7ebc8-f305-428e-b15e-bdbea2bd156a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df, end='\\n\\n')\n",
        "print(df.values, end='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kj9513eCMFf",
        "outputId": "0a40859d-c850-4c3e-878b-daf7d035a05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Girth  Height  Volume\n",
            "1     8.3      70    10.3\n",
            "2     8.6      65    10.3\n",
            "3     8.8      63    10.2\n",
            "4    10.5      72    16.4\n",
            "5    10.7      81    18.8\n",
            "6    10.8      83    19.7\n",
            "7    11.0      66    15.6\n",
            "8    11.0      75    18.2\n",
            "9    11.1      80    22.6\n",
            "10   11.2      75    19.9\n",
            "11   11.3      79    24.2\n",
            "12   11.4      76    21.0\n",
            "13   11.4      76    21.4\n",
            "14   11.7      69    21.3\n",
            "15   12.0      75    19.1\n",
            "16   12.9      74    22.2\n",
            "17   12.9      85    33.8\n",
            "18   13.3      86    27.4\n",
            "19   13.7      71    25.7\n",
            "20   13.8      64    24.9\n",
            "21   14.0      78    34.5\n",
            "22   14.2      80    31.7\n",
            "23   14.5      74    36.3\n",
            "24   16.0      72    38.3\n",
            "25   16.3      77    42.6\n",
            "26   17.3      81    55.4\n",
            "27   17.5      82    55.7\n",
            "28   17.9      80    58.3\n",
            "29   18.0      80    51.5\n",
            "30   18.0      80    51.0\n",
            "31   20.6      87    77.0\n",
            "\n",
            "[[ 8.3 70.  10.3]\n",
            " [ 8.6 65.  10.3]\n",
            " [ 8.8 63.  10.2]\n",
            " [10.5 72.  16.4]\n",
            " [10.7 81.  18.8]\n",
            " [10.8 83.  19.7]\n",
            " [11.  66.  15.6]\n",
            " [11.  75.  18.2]\n",
            " [11.1 80.  22.6]\n",
            " [11.2 75.  19.9]\n",
            " [11.3 79.  24.2]\n",
            " [11.4 76.  21. ]\n",
            " [11.4 76.  21.4]\n",
            " [11.7 69.  21.3]\n",
            " [12.  75.  19.1]\n",
            " [12.9 74.  22.2]\n",
            " [12.9 85.  33.8]\n",
            " [13.3 86.  27.4]\n",
            " [13.7 71.  25.7]\n",
            " [13.8 64.  24.9]\n",
            " [14.  78.  34.5]\n",
            " [14.2 80.  31.7]\n",
            " [14.5 74.  36.3]\n",
            " [16.  72.  38.3]\n",
            " [16.3 77.  42.6]\n",
            " [17.3 81.  55.4]\n",
            " [17.5 82.  55.7]\n",
            " [17.9 80.  58.3]\n",
            " [18.  80.  51.5]\n",
            " [18.  80.  51. ]\n",
            " [20.6 87.  77. ]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.values[:, :-1]\n",
        "# y = df.values[:, -1] # 1차원\n",
        "y = df.values[:, -1:]   # 2차원\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ov0IQmCXXB",
        "outputId": "5351b395-eed5-48c2-d419-0cc1026299eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31, 2) (31, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quize\n",
        "# trees.csv 파일을 읽고 학습하는 모델을 구축해서\n",
        "# Birth 가 15이고 Height = 70 인 나무와, \n",
        "# Birth 가 20이고 Height = 80 인 나무의 Volume을 구하세요"
      ],
      "metadata": {
        "id": "PoseksW_ChZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=[2]))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpi74t9-DqHj",
        "outputId": "6e5013ff-2527-4cbd-f6b9-f45b059c70b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(0.00007),\n",
        "              loss=tf.keras.losses.mse)\n",
        "\n",
        "model.fit(x, y, epochs=1000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6JowKC-FdnK",
        "outputId": "2d56521f-4855-48c1-9364-b93f2a774684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 59.1957\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 59.1492\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 59.1028\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 59.0565\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 59.0102\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 58.9641\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 58.9180\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 58.8721\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 58.8262\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 58.7804\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 58.7347\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.6891\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 58.6436\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.5982\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 58.5528\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 58.5076\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 58.4625\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.4174\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.3724\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.3275\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.2827\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 58.2380\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 58.1933\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.1488\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.1044\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.0600\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.0157\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.9715\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.9274\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.8834\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.8395\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.7956\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.7518\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.7082\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.6646\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.6211\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.5776\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.5343\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 57.4910\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.4479\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.4048\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.3618\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.3189\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.2760\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.2333\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.1906\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 57.1480\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.1056\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.0631\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.0208\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.9786\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 56.9364\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.8943\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.8523\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 56.8104\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.7686\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 56.7268\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 56.6851\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 56.6436\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.6021\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.5606\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.5193\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.4780\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.4368\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.3957\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.3547\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.3138\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.2729\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.2321\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.1914\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.1508\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.1103\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.0698\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.0294\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.9891\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.9489\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 55.9088\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.8687\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.8287\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.7888\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 55.7489\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 55.7092\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 55.6695\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.6299\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.5904\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 55.5509\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.5116\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.4723\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.4331\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 55.3940\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 55.3549\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 55.3159\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.2770\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.2382\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.1994\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.1607\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.1221\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.0836\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.0451\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.0068\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.9685\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.9302\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.8921\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.8540\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.8160\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 54.7781\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.7402\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.7025\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.6648\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.6271\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 54.5896\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 54.5521\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.5147\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.4773\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.4401\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 54.4029\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 54.3658\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.3287\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.2917\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.2548\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.2180\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.1812\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.1446\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.1080\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.0714\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.0349\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.9986\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.9622\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.9260\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.8898\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.8537\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.8176\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.7817\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.7458\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.7099\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.6742\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.6385\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.6028\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 53.5673\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.5318\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 53.4964\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.4611\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.4258\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.3906\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.3554\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 53.3204\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 53.2854\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.2504\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.2156\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.1808\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 53.1461\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 53.1114\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.0768\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.0423\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.0078\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.9735\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.9392\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.9049\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.8707\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.8366\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.8025\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.7686\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 52.7346\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.7008\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.6670\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.6333\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.5996\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.5660\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.5325\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.4991\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.4657\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 52.4323\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.3991\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.3659\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.3328\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.2997\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.2667\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 52.2338\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.2009\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.1681\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.1354\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.1027\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.0701\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.0375\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.0050\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.9726\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.9402\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.9080\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.8757\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.8435\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.8114\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.7794\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.7474\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.7155\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.6836\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.6519\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.6201\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.5884\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.5568\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.5253\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 51.4938\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.4624\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.4310\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.3997\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.3685\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.3373\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.3062\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.2751\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.2441\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.2132\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.1823\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.1515\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.1207\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.0900\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 51.0594\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 51.0289\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 50.9983\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 50.9679\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.9375\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 50.9071\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.8769\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.8467\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.8165\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.7864\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.7564\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.7264\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.6965\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.6666\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.6368\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.6071\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.5774\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.5478\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 50.5182\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.4887\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.4592\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.4298\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.4005\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.3712\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 50.3420\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.3128\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.2837\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.2547\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.2257\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.1967\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.1678\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.1390\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.1102\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.0815\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.0529\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.0243\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.9957\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.9672\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.9388\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.9104\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.8821\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.8538\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.8256\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.7975\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.7694\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.7413\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.7133\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.6854\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.6575\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.6297\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.6019\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.5742\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.5466\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.5189\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.4914\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.4639\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.4364\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.4090\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 49.3817\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.3544\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.3272\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.3000\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.2729\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.2458\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.2188\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.1918\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.1649\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.1380\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.1112\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.0845\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.0578\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.0311\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.0045\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.9780\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.9515\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.9250\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.8986\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.8723\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.8460\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.8198\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.7936\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.7674\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.7414\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.7153\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.6893\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.6634\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.6375\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.6117\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.5859\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.5602\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.5345\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.5089\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.4833\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.4578\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.4323\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.4069\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.3815\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.3562\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.3309\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.3056\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.2805\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.2554\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.2303\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 48.2052\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.1802\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.1553\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 48.1304\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 48.1056\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.0808\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.0561\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 48.0314\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.0067\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.9821\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.9576\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.9331\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.9086\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.8842\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 47.8599\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.8356\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.8113\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.7871\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.7629\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.7388\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.7147\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.6907\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.6667\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 47.6428\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.6189\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.5951\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.5713\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.5476\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 47.5239\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 47.5002\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.4766\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.4530\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.4295\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 47.4061\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.3826\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 47.3593\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.3359\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.3127\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 47.2894\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.2662\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.2431\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.2200\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.1969\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 47.1739\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.1510\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 47.1280\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.1052\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.0823\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.0596\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 47.0368\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.0141\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.9915\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.9688\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.9463\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.9237\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 46.9013\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.8789\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 46.8565\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.8341\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.8118\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.7896\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.7673\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.7452\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.7231\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.7010\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.6789\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.6569\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.6350\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.6131\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.5912\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.5694\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.5476\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.5258\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.5042\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 46.4825\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 46.4609\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.4393\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.4178\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.3963\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 46.3749\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 46.3534\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 46.3321\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 46.3108\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 46.2895\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 46.2683\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 46.2471\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.2259\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.2048\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.1838\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.1627\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.1417\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.1208\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 46.0999\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 46.0790\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 46.0582\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.0374\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.0167\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.9960\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.9753\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.9547\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.9341\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.9136\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.8931\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.8726\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.8522\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.8318\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.8115\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.7912\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 45.7709\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.7507\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.7305\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.7104\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.6903\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 45.6702\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 45.6502\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 45.6302\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 45.6103\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.5904\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.5705\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.5507\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.5309\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.5111\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 45.4914\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.4717\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.4521\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 45.4325\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.4129\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.3934\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.3740\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.3545\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.3351\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.3157\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.2964\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.2771\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.2579\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.2386\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.2195\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.2003\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.1812\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 45.1622\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.1431\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.1241\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.1052\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.0863\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.0674\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.0485\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.0297\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 45.0110\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.9922\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.9735\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.9549\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.9363\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 44.9177\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.8991\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.8806\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.8621\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.8437\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.8253\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.8069\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.7886\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.7703\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.7520\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.7338\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.7156\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.6974\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.6793\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.6612\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.6432\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.6252\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.6072\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5893\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5714\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5535\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5356\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5178\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5001\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.4823\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.4646\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.4470\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.4293\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.4117\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 44.3942\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.3767\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.3592\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.3417\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.3243\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.3069\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.2895\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.2722\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.2549\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.2377\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.2204\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.2033\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.1861\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.1690\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.1519\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.1349\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.1178\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.1009\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.0839\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.0670\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.0501\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.0332\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.0164\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.9996\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 43.9829\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.9662\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.9495\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.9328\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.9162\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.8996\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.8830\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.8665\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.8500\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.8336\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.8171\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.8007\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.7844\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 43.7680\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.7517\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.7355\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.7192\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.7030\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.6868\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.6707\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.6546\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.6385\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.6225\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.6064\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.5905\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.5745\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.5586\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.5427\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.5268\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.5110\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4952\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.4794\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4637\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.4480\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4323\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4166\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4010\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.3854\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.3699\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.3544\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 43.3389\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 43.3234\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.3080\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.2926\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.2772\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.2619\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.2466\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 43.2313\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.2160\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.2008\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1856\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1704\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.1553\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1402\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1251\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1101\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.0951\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.0801\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.0651\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.0502\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.0353\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.0204\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.0056\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.9908\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.9760\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.9613\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.9465\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.9318\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.9172\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.9025\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.8879\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.8734\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.8588\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.8443\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.8298\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.8153\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.8009\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.7864\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.7721\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 42.7577\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 42.7434\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.7291\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.7148\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 42.7006\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 42.6863\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.6721\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.6580\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.6439\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 42.6298\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 42.6157\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 42.6016\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.5876\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 42.5736\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.5597\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.5457\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.5318\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.5179\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.5041\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.4903\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.4765\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.4627\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.4490\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.4352\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.4215\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.4078\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.3942\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.3806\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.3670\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.3534\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.3399\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.3264\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.3129\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.2994\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.2860\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 42.2726\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.2592\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.2459\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.2325\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.2192\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.2060\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.1927\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.1795\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.1663\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 42.1531\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.1400\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 42.1269\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.1138\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 42.1007\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.0877\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.0746\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.0617\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.0487\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 42.0358\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.0228\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.0099\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.9971\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.9842\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.9714\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.9586\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.9459\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.9331\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.9204\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.9077\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.8951\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.8824\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.8698\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.8572\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.8447\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.8321\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.8196\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.8071\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 41.7946\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 41.7822\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.7698\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.7574\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.7450\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 41.7327\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 41.7203\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.7080\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 41.6958\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.6835\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.6713\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.6591\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.6469\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 41.6347\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.6226\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 41.6105\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.5984\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.5864\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.5743\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.5623\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 41.5503\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.5384\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.5264\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.5145\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.5026\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.4907\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.4789\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.4670\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.4552\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.4435\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.4317\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.4200\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.4083\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.3966\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.3849\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.3733\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.3616\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.3500\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.3385\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.3269\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.3154\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.3039\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 41.2924\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.2809\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.2695\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.2581\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.2467\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.2353\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.2239\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.2126\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.2013\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.1900\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.1788\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.1675\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.1563\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.1451\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.1339\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.1228\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.1116\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 41.1005\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.0895\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.0784\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.0673\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.0563\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.0453\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.0343\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.0234\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.0124\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 41.0015\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.9906\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.9798\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.9689\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.9581\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.9473\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.9365\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.9257\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.9150\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.9042\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.8935\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 40.8828\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 40.8722\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 40.8615\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.8509\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.8403\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 40.8297\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.8192\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.8086\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7981\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7876\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7771\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7667\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7563\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7458\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7355\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.7251\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.7147\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7044\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6941\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6838\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 40.6735\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.6632\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6530\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6428\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.6326\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6224\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6123\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6022\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5920\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5820\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5719\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5618\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5518\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5418\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5318\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.5218\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.5118\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.5019\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.4920\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.4821\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.4722\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.4623\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 40.4525\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.4427\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.4329\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.4231\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.4133\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.4036\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.3939\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.3841\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.3745\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.3648\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.3551\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.3455\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.3359\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.3263\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.3167\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.3072\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.2976\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.2881\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.2786\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.2691\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.2597\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.2502\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.2408\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 40.2314\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 40.2220\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.2126\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.2033\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.1939\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 40.1846\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.1753\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.1660\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.1568\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.1475\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.1383\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.1291\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.1199\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.1107\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.1016\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.0924\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.0833\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 40.0742\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.0651\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.0561\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.0470\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.0380\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.0290\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 40.0200\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.0110\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.0020\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.9931\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.9842\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.9753\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 39.9664\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.9575\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.9486\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.9398\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.9310\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.9222\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 39.9134\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.9046\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.8959\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 39.8872\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8784\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8697\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.8610\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8524\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8437\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8351\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8265\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8179\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.8093\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.8007\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.7922\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.7836\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.7751\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.7666\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.7581\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.7497\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.7412\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.7328\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.7244\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.7160\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 39.7076\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.6992\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.6909\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.6825\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.6742\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.6659\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.6576\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.6493\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.6411\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 39.6329\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.6246\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.6164\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.6082\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.6001\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.5919\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.5838\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.5756\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.5675\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.5594\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.5514\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.5433\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.5352\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.5272\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.5192\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.5112\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.5032\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.4952\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.4873\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.4794\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.4714\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.4635\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.4556\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 39.4477\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 39.4399\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 39.4320\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 39.4242\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 39.4164\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 39.4086\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.4008\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.3930\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3853\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3775\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3698\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3621\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3544\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3467\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3391\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3314\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3238\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3162\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.3086\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.3010\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2934\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2858\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.2783\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2708\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2633\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.2557\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.2483\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2408\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.2333\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2259\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2185\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2111\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.2036\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.1963\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.1889\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 39.1815\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.1742\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.1669\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 39.1596\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.1523\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 39.1450\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.1377\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.1305\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 39.1232\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.1160\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.1088\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.1016\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.0944\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.0872\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.0800\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.0729\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.0658\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.0587\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.0516\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.0445\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.0374\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 39.0303\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.0233\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.0162\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 39.0092\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.0022\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 38.9952\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9883\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9813\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 38.9743\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 38.9674\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 38.9605\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9536\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9467\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9398\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 38.9329\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9260\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9192\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9124\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.9056\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 38.8988\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.8920\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.8852\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 38.8784\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 38.8717\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.8649\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.8582\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.8515\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 38.8448\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.8381\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 38.8314\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 38.8248\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 38.8181\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 38.8115\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 38.8049\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.7983\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 38.7917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6dc1479a10>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([[15, 70],\n",
        "                                 [20, 80]], verbose=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnWW7nkHFn3k",
        "outputId": "bbbe2887-87d7-40b6-da4d-48e73a9381cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[40.377457]\n",
            " [58.627125]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_2_2_logistic_regression"
      ],
      "metadata": {
        "id": "KOxRy9rGNPv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "print(np.e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCvVWMpIF3rE",
        "outputId": "7200b31f-f393-44fa-bfc8-fbcdd65e635f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.718281828459045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sigmoid():\n",
        "    # z = wx + b\n",
        "    def sigmoid(z):\n",
        "        return 1 / (1 + np.e ** -z)\n",
        "\n",
        "    for z in np.linspace(-10, 10, 100):\n",
        "        s = sigmoid(z)\n",
        "        plt.plot(z, s, 'ro')\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rqwOXahsNhsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression():\n",
        "\n",
        "    # 공부시간, 출석일수\n",
        "    x = [[1, 2],  # 탈락\n",
        "        [2, 1],\n",
        "        [4, 5],     # 통과\n",
        "        [5, 4],\n",
        "        [8, 9],\n",
        "        [9, 8]]\n",
        "    y = [[0],\n",
        "        [0],\n",
        "        [1],\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]]\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=[2]))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.summary()    \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
        "                loss=tf.keras.losses.binary_crossentropy,\n",
        "                metrics='acc')\n",
        "\n",
        "    model.fit(x, y, epochs=100, verbose=2)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "Si6UoCm6OVcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = logistic_regression()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHkuc5fFocpP",
        "outputId": "02640afa-b856-4294-8a47-48099cc5c9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 - 0s - loss: 2.0960 - acc: 0.3333 - 339ms/epoch - 339ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 1.7921 - acc: 0.3333 - 9ms/epoch - 9ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 1.5118 - acc: 0.3333 - 9ms/epoch - 9ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 1.2633 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 1.0544 - acc: 0.3333 - 9ms/epoch - 9ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 0.8893 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 0.7663 - acc: 0.3333 - 10ms/epoch - 10ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 0.6780 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 0.6155 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 0.5710 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 0.5387 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 0.5147 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 0.4966 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 0.4825 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 0.4715 - acc: 0.6667 - 10ms/epoch - 10ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 0.4626 - acc: 0.6667 - 13ms/epoch - 13ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 0.4554 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 0.4494 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 0.4444 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 0.4403 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 0.4367 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 0.4337 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.4310 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.4287 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.4267 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.4250 - acc: 0.6667 - 11ms/epoch - 11ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.4234 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.4220 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.4207 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.4196 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.4186 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.4176 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.4168 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.4160 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.4153 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.4146 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.4140 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.4134 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.4128 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.4123 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.4118 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.4114 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.4110 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.4105 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.4101 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.4098 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.4094 - acc: 0.6667 - 11ms/epoch - 11ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.4090 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.4087 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.4084 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.4080 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.4077 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.4074 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.4071 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.4068 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.4065 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.4063 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.4060 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.4057 - acc: 0.6667 - 11ms/epoch - 11ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.4054 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.4052 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.4049 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.4047 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.4044 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.4042 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.4039 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.4037 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.4034 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.4032 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.4029 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.4027 - acc: 0.6667 - 15ms/epoch - 15ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.4024 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.4022 - acc: 0.6667 - 12ms/epoch - 12ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.4020 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.4017 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.4015 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.4013 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.4010 - acc: 0.6667 - 11ms/epoch - 11ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.4008 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.4006 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.4003 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.4001 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.3999 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.3997 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.3994 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.3992 - acc: 0.6667 - 10ms/epoch - 10ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.3990 - acc: 0.6667 - 10ms/epoch - 10ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.3988 - acc: 0.6667 - 10ms/epoch - 10ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.3985 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.3983 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.3981 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.3979 - acc: 0.6667 - 11ms/epoch - 11ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.3976 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.3974 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.3972 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.3970 - acc: 0.6667 - 14ms/epoch - 14ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.3967 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.3965 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.3963 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.3961 - acc: 0.6667 - 9ms/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 공부시간, 출석일수\n",
        "x = [[1, 2],  # 탈락\n",
        "    [2, 1],\n",
        "    [4, 5],     # 통과\n",
        "    [5, 4],\n",
        "    [8, 9],\n",
        "    [9, 8]]\n",
        "y = [[0],\n",
        "    [0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1],\n",
        "    [1]]\n",
        "print(model.evaluate(x, y, verbose=0)) # loss, accuarcy 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLf94bFeoUfG",
        "outputId": "05ed6863-c06d-4b8d-a243-f6847e1cfd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3958665132522583, 0.6666666865348816]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quize\n",
        "# 5시간 공부하고 2번 출석한 학생과\n",
        "# 3시간 공부하고 6번 출석한 학생의 성적을 구하세요\n",
        "p = model.predict(x, verbose=0)\n",
        "print(p)\n",
        "print(model.predict([[5, 2],\n",
        "                                [3, 6]], verbose=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIWqnmL1oRGL",
        "outputId": "66102f98-b86c-4520-bca7-9c41197a4293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.61954546]\n",
            " [0.6310551 ]\n",
            " [0.84162545]\n",
            " [0.84806424]\n",
            " [0.9625787 ]\n",
            " [0.9643087 ]]\n",
            "1/1 - 0s - 28ms/epoch - 28ms/step\n",
            "[[0.7980859 ]\n",
            " [0.83496684]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_bool = np.int32(p > 0.5)\n",
        "p_bool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUB4gC-ASfA7",
        "outputId": "5d79aabd-50d0-4ab5-a8f6-78be5b14a835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "equals = (p_bool == y)\n",
        "print(equals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rvnuRfzo3pv",
        "outputId": "4c9745f1-ad49-49ce-9575-efe2a4a4dddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('acc :', np.mean(equals))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILQEnlLco4kO",
        "outputId": "b44b14d5-83d2-42e8-8f57-822677ee8883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc : 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_2_3_pima.py"
      ],
      "metadata": {
        "id": "0G2OAxPzruCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quiz\n",
        "피마 인디언 당뇨변 데이터에 대한 모델을 구축하세요."
      ],
      "metadata": {
        "id": "RqEGDtjGs9T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing, model_selection\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MRe92geo4fyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/pima-indians-diabetes.csv\")"
      ],
      "metadata": {
        "id": "xuhJtVDZpUtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "상단에 주석과 같은 필요없는 글이 있을 때,\n",
        "pd.read_csv() 파라미터 skiprows 를 통해 무시할 행의 갯수를 표기한다.\n",
        "또한 header=None 를 통해 첫번째 행을 칼럼명으로 가져오는 것을 방지한다."
      ],
      "metadata": {
        "id": "aoIhdOYRxlbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/pima-indians-diabetes.csv\", \n",
        "                #  skiprows = 9, # -> 삭제했기 때문에 주석처리\n",
        "                 header = None)"
      ],
      "metadata": {
        "id": "csEEmZPkyWzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/pima-indians-diabetes.csv\")"
      ],
      "metadata": {
        "id": "hkz6yG84yQnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0xRMZatDscKH",
        "outputId": "dfbf17b3-8da9-45c6-c2c8-224be419f5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   6  148  72  35    0  33.6  0.627  50  1\n",
              "0  1   85  66  29    0  26.6  0.351  31  0\n",
              "1  8  183  64   0    0  23.3  0.672  32  1\n",
              "2  1   89  66  23   94  28.1  0.167  21  0\n",
              "3  0  137  40  35  168  43.1  2.288  33  1\n",
              "4  5  116  74   0    0  25.6  0.201  30  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa62aa11-1b2a-4b6e-b227-a67f6c2b34ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6</th>\n",
              "      <th>148</th>\n",
              "      <th>72</th>\n",
              "      <th>35</th>\n",
              "      <th>0</th>\n",
              "      <th>33.6</th>\n",
              "      <th>0.627</th>\n",
              "      <th>50</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa62aa11-1b2a-4b6e-b227-a67f6c2b34ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa62aa11-1b2a-4b6e-b227-a67f6c2b34ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa62aa11-1b2a-4b6e-b227-a67f6c2b34ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_name = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']"
      ],
      "metadata": {
        "id": "8j_IzBCMvkaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/pima-indians-diabetes.csv\", names = columns_name)"
      ],
      "metadata": {
        "id": "n12nFxe7u_ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rUS3v4aXv4XE",
        "outputId": "d6e85a1d-3e0f-4844-ac76-9e8a16301e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa0415cb-0c48-43c9-a2e9-8dceeb46394b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa0415cb-0c48-43c9-a2e9-8dceeb46394b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa0415cb-0c48-43c9-a2e9-8dceeb46394b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa0415cb-0c48-43c9-a2e9-8dceeb46394b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(x, y):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=[8]))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.summary()    \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(0.001),\n",
        "                loss=tf.keras.losses.binary_crossentropy,\n",
        "                metrics='acc')\n",
        "\n",
        "    model.fit(x, y, epochs=200, verbose=2)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "q7pbCWPBv99B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.values[:, :-1]\n",
        "# y = df.values[:, -1] # 1차원\n",
        "y = df.values[:, -1:]   # 2차원\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEFNZOfLwWRV",
        "outputId": "77e34c8f-fa94-46c1-ff8f-1633b28e3e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 8) (768, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train test split"
      ],
      "metadata": {
        "id": "R3X1z7HF52e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 주먹구구 식\n",
        "train_size = int(len(x) * 0.7)\n",
        "x_train, x_test = x[:train_size], x[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]"
      ],
      "metadata": {
        "id": "Mbdl2NBV6Bw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = model_selection.train_test_split(x, y, train_size=0.75, shuffle=True) \n",
        "# (Tip) command 함수 클릭 -> 함수의 파라미터 도움말를 볼 수 있음\n",
        "x_train, x_test, y_train, y_test = data"
      ],
      "metadata": {
        "id": "zWowuT8C8Abw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dftrnqn8UE7",
        "outputId": "81d4eca4-2bbc-47b8-8649-32a71e2c1353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(576, 8) (576, 1)\n",
            "(192, 8) (192, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg3CVcSR3ZNt",
        "outputId": "7a93d1c8-dcea-4a7c-e87d-23498f797875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(537, 8) (537, 1)\n",
            "(231, 8) (231, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습데이터 스케일링 \n",
        "- normalization\n",
        "- minmax\n",
        "- standardization"
      ],
      "metadata": {
        "id": "24sACTIQ5OiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x = preprocessing.scale(x)\n",
        "# x = preprocessing.minmax_scale(x)"
      ],
      "metadata": {
        "id": "-LSGnlfl4qsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "5T7DDc017Hht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = logistic_regression(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSUFqWzewLBb",
        "outputId": "776a239e-f60c-4040-fefc-425ccd41f596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "18/18 - 0s - loss: 0.7073 - acc: 0.5660 - 311ms/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "18/18 - 0s - loss: 0.7050 - acc: 0.5694 - 35ms/epoch - 2ms/step\n",
            "Epoch 3/200\n",
            "18/18 - 0s - loss: 0.7026 - acc: 0.5712 - 37ms/epoch - 2ms/step\n",
            "Epoch 4/200\n",
            "18/18 - 0s - loss: 0.7003 - acc: 0.5729 - 35ms/epoch - 2ms/step\n",
            "Epoch 5/200\n",
            "18/18 - 0s - loss: 0.6981 - acc: 0.5747 - 35ms/epoch - 2ms/step\n",
            "Epoch 6/200\n",
            "18/18 - 0s - loss: 0.6958 - acc: 0.5747 - 37ms/epoch - 2ms/step\n",
            "Epoch 7/200\n",
            "18/18 - 0s - loss: 0.6936 - acc: 0.5764 - 35ms/epoch - 2ms/step\n",
            "Epoch 8/200\n",
            "18/18 - 0s - loss: 0.6914 - acc: 0.5799 - 35ms/epoch - 2ms/step\n",
            "Epoch 9/200\n",
            "18/18 - 0s - loss: 0.6893 - acc: 0.5833 - 36ms/epoch - 2ms/step\n",
            "Epoch 10/200\n",
            "18/18 - 0s - loss: 0.6871 - acc: 0.5868 - 38ms/epoch - 2ms/step\n",
            "Epoch 11/200\n",
            "18/18 - 0s - loss: 0.6850 - acc: 0.5903 - 36ms/epoch - 2ms/step\n",
            "Epoch 12/200\n",
            "18/18 - 0s - loss: 0.6829 - acc: 0.5938 - 42ms/epoch - 2ms/step\n",
            "Epoch 13/200\n",
            "18/18 - 0s - loss: 0.6809 - acc: 0.5955 - 45ms/epoch - 3ms/step\n",
            "Epoch 14/200\n",
            "18/18 - 0s - loss: 0.6788 - acc: 0.5972 - 35ms/epoch - 2ms/step\n",
            "Epoch 15/200\n",
            "18/18 - 0s - loss: 0.6768 - acc: 0.5972 - 36ms/epoch - 2ms/step\n",
            "Epoch 16/200\n",
            "18/18 - 0s - loss: 0.6748 - acc: 0.5972 - 36ms/epoch - 2ms/step\n",
            "Epoch 17/200\n",
            "18/18 - 0s - loss: 0.6729 - acc: 0.6007 - 38ms/epoch - 2ms/step\n",
            "Epoch 18/200\n",
            "18/18 - 0s - loss: 0.6709 - acc: 0.6042 - 37ms/epoch - 2ms/step\n",
            "Epoch 19/200\n",
            "18/18 - 0s - loss: 0.6690 - acc: 0.6024 - 38ms/epoch - 2ms/step\n",
            "Epoch 20/200\n",
            "18/18 - 0s - loss: 0.6671 - acc: 0.6042 - 36ms/epoch - 2ms/step\n",
            "Epoch 21/200\n",
            "18/18 - 0s - loss: 0.6652 - acc: 0.6024 - 35ms/epoch - 2ms/step\n",
            "Epoch 22/200\n",
            "18/18 - 0s - loss: 0.6634 - acc: 0.6024 - 38ms/epoch - 2ms/step\n",
            "Epoch 23/200\n",
            "18/18 - 0s - loss: 0.6616 - acc: 0.6076 - 37ms/epoch - 2ms/step\n",
            "Epoch 24/200\n",
            "18/18 - 0s - loss: 0.6598 - acc: 0.6094 - 40ms/epoch - 2ms/step\n",
            "Epoch 25/200\n",
            "18/18 - 0s - loss: 0.6580 - acc: 0.6111 - 36ms/epoch - 2ms/step\n",
            "Epoch 26/200\n",
            "18/18 - 0s - loss: 0.6562 - acc: 0.6128 - 36ms/epoch - 2ms/step\n",
            "Epoch 27/200\n",
            "18/18 - 0s - loss: 0.6544 - acc: 0.6128 - 36ms/epoch - 2ms/step\n",
            "Epoch 28/200\n",
            "18/18 - 0s - loss: 0.6527 - acc: 0.6111 - 34ms/epoch - 2ms/step\n",
            "Epoch 29/200\n",
            "18/18 - 0s - loss: 0.6510 - acc: 0.6094 - 35ms/epoch - 2ms/step\n",
            "Epoch 30/200\n",
            "18/18 - 0s - loss: 0.6493 - acc: 0.6111 - 36ms/epoch - 2ms/step\n",
            "Epoch 31/200\n",
            "18/18 - 0s - loss: 0.6477 - acc: 0.6128 - 35ms/epoch - 2ms/step\n",
            "Epoch 32/200\n",
            "18/18 - 0s - loss: 0.6460 - acc: 0.6198 - 34ms/epoch - 2ms/step\n",
            "Epoch 33/200\n",
            "18/18 - 0s - loss: 0.6444 - acc: 0.6215 - 35ms/epoch - 2ms/step\n",
            "Epoch 34/200\n",
            "18/18 - 0s - loss: 0.6428 - acc: 0.6250 - 35ms/epoch - 2ms/step\n",
            "Epoch 35/200\n",
            "18/18 - 0s - loss: 0.6412 - acc: 0.6250 - 33ms/epoch - 2ms/step\n",
            "Epoch 36/200\n",
            "18/18 - 0s - loss: 0.6396 - acc: 0.6250 - 34ms/epoch - 2ms/step\n",
            "Epoch 37/200\n",
            "18/18 - 0s - loss: 0.6380 - acc: 0.6285 - 52ms/epoch - 3ms/step\n",
            "Epoch 38/200\n",
            "18/18 - 0s - loss: 0.6365 - acc: 0.6285 - 34ms/epoch - 2ms/step\n",
            "Epoch 39/200\n",
            "18/18 - 0s - loss: 0.6350 - acc: 0.6302 - 35ms/epoch - 2ms/step\n",
            "Epoch 40/200\n",
            "18/18 - 0s - loss: 0.6335 - acc: 0.6302 - 37ms/epoch - 2ms/step\n",
            "Epoch 41/200\n",
            "18/18 - 0s - loss: 0.6320 - acc: 0.6319 - 36ms/epoch - 2ms/step\n",
            "Epoch 42/200\n",
            "18/18 - 0s - loss: 0.6305 - acc: 0.6354 - 36ms/epoch - 2ms/step\n",
            "Epoch 43/200\n",
            "18/18 - 0s - loss: 0.6291 - acc: 0.6406 - 35ms/epoch - 2ms/step\n",
            "Epoch 44/200\n",
            "18/18 - 0s - loss: 0.6276 - acc: 0.6424 - 40ms/epoch - 2ms/step\n",
            "Epoch 45/200\n",
            "18/18 - 0s - loss: 0.6262 - acc: 0.6458 - 35ms/epoch - 2ms/step\n",
            "Epoch 46/200\n",
            "18/18 - 0s - loss: 0.6248 - acc: 0.6510 - 40ms/epoch - 2ms/step\n",
            "Epoch 47/200\n",
            "18/18 - 0s - loss: 0.6234 - acc: 0.6528 - 36ms/epoch - 2ms/step\n",
            "Epoch 48/200\n",
            "18/18 - 0s - loss: 0.6220 - acc: 0.6528 - 45ms/epoch - 2ms/step\n",
            "Epoch 49/200\n",
            "18/18 - 0s - loss: 0.6207 - acc: 0.6545 - 36ms/epoch - 2ms/step\n",
            "Epoch 50/200\n",
            "18/18 - 0s - loss: 0.6193 - acc: 0.6545 - 36ms/epoch - 2ms/step\n",
            "Epoch 51/200\n",
            "18/18 - 0s - loss: 0.6180 - acc: 0.6562 - 38ms/epoch - 2ms/step\n",
            "Epoch 52/200\n",
            "18/18 - 0s - loss: 0.6167 - acc: 0.6615 - 41ms/epoch - 2ms/step\n",
            "Epoch 53/200\n",
            "18/18 - 0s - loss: 0.6154 - acc: 0.6597 - 38ms/epoch - 2ms/step\n",
            "Epoch 54/200\n",
            "18/18 - 0s - loss: 0.6141 - acc: 0.6649 - 36ms/epoch - 2ms/step\n",
            "Epoch 55/200\n",
            "18/18 - 0s - loss: 0.6128 - acc: 0.6684 - 38ms/epoch - 2ms/step\n",
            "Epoch 56/200\n",
            "18/18 - 0s - loss: 0.6115 - acc: 0.6701 - 35ms/epoch - 2ms/step\n",
            "Epoch 57/200\n",
            "18/18 - 0s - loss: 0.6103 - acc: 0.6701 - 37ms/epoch - 2ms/step\n",
            "Epoch 58/200\n",
            "18/18 - 0s - loss: 0.6091 - acc: 0.6719 - 37ms/epoch - 2ms/step\n",
            "Epoch 59/200\n",
            "18/18 - 0s - loss: 0.6078 - acc: 0.6736 - 41ms/epoch - 2ms/step\n",
            "Epoch 60/200\n",
            "18/18 - 0s - loss: 0.6066 - acc: 0.6771 - 45ms/epoch - 3ms/step\n",
            "Epoch 61/200\n",
            "18/18 - 0s - loss: 0.6054 - acc: 0.6771 - 40ms/epoch - 2ms/step\n",
            "Epoch 62/200\n",
            "18/18 - 0s - loss: 0.6043 - acc: 0.6771 - 34ms/epoch - 2ms/step\n",
            "Epoch 63/200\n",
            "18/18 - 0s - loss: 0.6031 - acc: 0.6806 - 47ms/epoch - 3ms/step\n",
            "Epoch 64/200\n",
            "18/18 - 0s - loss: 0.6019 - acc: 0.6806 - 59ms/epoch - 3ms/step\n",
            "Epoch 65/200\n",
            "18/18 - 0s - loss: 0.6008 - acc: 0.6788 - 54ms/epoch - 3ms/step\n",
            "Epoch 66/200\n",
            "18/18 - 0s - loss: 0.5997 - acc: 0.6788 - 57ms/epoch - 3ms/step\n",
            "Epoch 67/200\n",
            "18/18 - 0s - loss: 0.5985 - acc: 0.6840 - 48ms/epoch - 3ms/step\n",
            "Epoch 68/200\n",
            "18/18 - 0s - loss: 0.5974 - acc: 0.6910 - 48ms/epoch - 3ms/step\n",
            "Epoch 69/200\n",
            "18/18 - 0s - loss: 0.5963 - acc: 0.6892 - 57ms/epoch - 3ms/step\n",
            "Epoch 70/200\n",
            "18/18 - 0s - loss: 0.5953 - acc: 0.6910 - 52ms/epoch - 3ms/step\n",
            "Epoch 71/200\n",
            "18/18 - 0s - loss: 0.5942 - acc: 0.6927 - 50ms/epoch - 3ms/step\n",
            "Epoch 72/200\n",
            "18/18 - 0s - loss: 0.5931 - acc: 0.6979 - 50ms/epoch - 3ms/step\n",
            "Epoch 73/200\n",
            "18/18 - 0s - loss: 0.5921 - acc: 0.6962 - 49ms/epoch - 3ms/step\n",
            "Epoch 74/200\n",
            "18/18 - 0s - loss: 0.5910 - acc: 0.6997 - 49ms/epoch - 3ms/step\n",
            "Epoch 75/200\n",
            "18/18 - 0s - loss: 0.5900 - acc: 0.6997 - 52ms/epoch - 3ms/step\n",
            "Epoch 76/200\n",
            "18/18 - 0s - loss: 0.5890 - acc: 0.6979 - 51ms/epoch - 3ms/step\n",
            "Epoch 77/200\n",
            "18/18 - 0s - loss: 0.5880 - acc: 0.7014 - 52ms/epoch - 3ms/step\n",
            "Epoch 78/200\n",
            "18/18 - 0s - loss: 0.5870 - acc: 0.6997 - 57ms/epoch - 3ms/step\n",
            "Epoch 79/200\n",
            "18/18 - 0s - loss: 0.5860 - acc: 0.7014 - 46ms/epoch - 3ms/step\n",
            "Epoch 80/200\n",
            "18/18 - 0s - loss: 0.5850 - acc: 0.7031 - 47ms/epoch - 3ms/step\n",
            "Epoch 81/200\n",
            "18/18 - 0s - loss: 0.5840 - acc: 0.7049 - 48ms/epoch - 3ms/step\n",
            "Epoch 82/200\n",
            "18/18 - 0s - loss: 0.5831 - acc: 0.7049 - 52ms/epoch - 3ms/step\n",
            "Epoch 83/200\n",
            "18/18 - 0s - loss: 0.5821 - acc: 0.7066 - 51ms/epoch - 3ms/step\n",
            "Epoch 84/200\n",
            "18/18 - 0s - loss: 0.5812 - acc: 0.7066 - 51ms/epoch - 3ms/step\n",
            "Epoch 85/200\n",
            "18/18 - 0s - loss: 0.5803 - acc: 0.7066 - 56ms/epoch - 3ms/step\n",
            "Epoch 86/200\n",
            "18/18 - 0s - loss: 0.5793 - acc: 0.7066 - 53ms/epoch - 3ms/step\n",
            "Epoch 87/200\n",
            "18/18 - 0s - loss: 0.5784 - acc: 0.7066 - 56ms/epoch - 3ms/step\n",
            "Epoch 88/200\n",
            "18/18 - 0s - loss: 0.5775 - acc: 0.7066 - 55ms/epoch - 3ms/step\n",
            "Epoch 89/200\n",
            "18/18 - 0s - loss: 0.5766 - acc: 0.7083 - 53ms/epoch - 3ms/step\n",
            "Epoch 90/200\n",
            "18/18 - 0s - loss: 0.5757 - acc: 0.7101 - 53ms/epoch - 3ms/step\n",
            "Epoch 91/200\n",
            "18/18 - 0s - loss: 0.5749 - acc: 0.7135 - 55ms/epoch - 3ms/step\n",
            "Epoch 92/200\n",
            "18/18 - 0s - loss: 0.5740 - acc: 0.7135 - 50ms/epoch - 3ms/step\n",
            "Epoch 93/200\n",
            "18/18 - 0s - loss: 0.5731 - acc: 0.7135 - 51ms/epoch - 3ms/step\n",
            "Epoch 94/200\n",
            "18/18 - 0s - loss: 0.5723 - acc: 0.7135 - 51ms/epoch - 3ms/step\n",
            "Epoch 95/200\n",
            "18/18 - 0s - loss: 0.5714 - acc: 0.7135 - 52ms/epoch - 3ms/step\n",
            "Epoch 96/200\n",
            "18/18 - 0s - loss: 0.5706 - acc: 0.7135 - 58ms/epoch - 3ms/step\n",
            "Epoch 97/200\n",
            "18/18 - 0s - loss: 0.5698 - acc: 0.7170 - 54ms/epoch - 3ms/step\n",
            "Epoch 98/200\n",
            "18/18 - 0s - loss: 0.5690 - acc: 0.7170 - 53ms/epoch - 3ms/step\n",
            "Epoch 99/200\n",
            "18/18 - 0s - loss: 0.5682 - acc: 0.7170 - 54ms/epoch - 3ms/step\n",
            "Epoch 100/200\n",
            "18/18 - 0s - loss: 0.5674 - acc: 0.7170 - 51ms/epoch - 3ms/step\n",
            "Epoch 101/200\n",
            "18/18 - 0s - loss: 0.5666 - acc: 0.7170 - 56ms/epoch - 3ms/step\n",
            "Epoch 102/200\n",
            "18/18 - 0s - loss: 0.5658 - acc: 0.7240 - 50ms/epoch - 3ms/step\n",
            "Epoch 103/200\n",
            "18/18 - 0s - loss: 0.5650 - acc: 0.7240 - 50ms/epoch - 3ms/step\n",
            "Epoch 104/200\n",
            "18/18 - 0s - loss: 0.5642 - acc: 0.7257 - 53ms/epoch - 3ms/step\n",
            "Epoch 105/200\n",
            "18/18 - 0s - loss: 0.5635 - acc: 0.7274 - 49ms/epoch - 3ms/step\n",
            "Epoch 106/200\n",
            "18/18 - 0s - loss: 0.5627 - acc: 0.7292 - 49ms/epoch - 3ms/step\n",
            "Epoch 107/200\n",
            "18/18 - 0s - loss: 0.5620 - acc: 0.7292 - 52ms/epoch - 3ms/step\n",
            "Epoch 108/200\n",
            "18/18 - 0s - loss: 0.5612 - acc: 0.7292 - 51ms/epoch - 3ms/step\n",
            "Epoch 109/200\n",
            "18/18 - 0s - loss: 0.5605 - acc: 0.7292 - 53ms/epoch - 3ms/step\n",
            "Epoch 110/200\n",
            "18/18 - 0s - loss: 0.5598 - acc: 0.7292 - 50ms/epoch - 3ms/step\n",
            "Epoch 111/200\n",
            "18/18 - 0s - loss: 0.5590 - acc: 0.7309 - 51ms/epoch - 3ms/step\n",
            "Epoch 112/200\n",
            "18/18 - 0s - loss: 0.5583 - acc: 0.7309 - 52ms/epoch - 3ms/step\n",
            "Epoch 113/200\n",
            "18/18 - 0s - loss: 0.5576 - acc: 0.7344 - 53ms/epoch - 3ms/step\n",
            "Epoch 114/200\n",
            "18/18 - 0s - loss: 0.5569 - acc: 0.7344 - 51ms/epoch - 3ms/step\n",
            "Epoch 115/200\n",
            "18/18 - 0s - loss: 0.5562 - acc: 0.7326 - 54ms/epoch - 3ms/step\n",
            "Epoch 116/200\n",
            "18/18 - 0s - loss: 0.5555 - acc: 0.7344 - 50ms/epoch - 3ms/step\n",
            "Epoch 117/200\n",
            "18/18 - 0s - loss: 0.5548 - acc: 0.7361 - 57ms/epoch - 3ms/step\n",
            "Epoch 118/200\n",
            "18/18 - 0s - loss: 0.5542 - acc: 0.7361 - 52ms/epoch - 3ms/step\n",
            "Epoch 119/200\n",
            "18/18 - 0s - loss: 0.5535 - acc: 0.7361 - 51ms/epoch - 3ms/step\n",
            "Epoch 120/200\n",
            "18/18 - 0s - loss: 0.5528 - acc: 0.7361 - 52ms/epoch - 3ms/step\n",
            "Epoch 121/200\n",
            "18/18 - 0s - loss: 0.5522 - acc: 0.7378 - 51ms/epoch - 3ms/step\n",
            "Epoch 122/200\n",
            "18/18 - 0s - loss: 0.5515 - acc: 0.7378 - 56ms/epoch - 3ms/step\n",
            "Epoch 123/200\n",
            "18/18 - 0s - loss: 0.5509 - acc: 0.7378 - 64ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "18/18 - 0s - loss: 0.5502 - acc: 0.7378 - 50ms/epoch - 3ms/step\n",
            "Epoch 125/200\n",
            "18/18 - 0s - loss: 0.5496 - acc: 0.7378 - 54ms/epoch - 3ms/step\n",
            "Epoch 126/200\n",
            "18/18 - 0s - loss: 0.5490 - acc: 0.7396 - 53ms/epoch - 3ms/step\n",
            "Epoch 127/200\n",
            "18/18 - 0s - loss: 0.5484 - acc: 0.7396 - 56ms/epoch - 3ms/step\n",
            "Epoch 128/200\n",
            "18/18 - 0s - loss: 0.5477 - acc: 0.7396 - 54ms/epoch - 3ms/step\n",
            "Epoch 129/200\n",
            "18/18 - 0s - loss: 0.5471 - acc: 0.7396 - 52ms/epoch - 3ms/step\n",
            "Epoch 130/200\n",
            "18/18 - 0s - loss: 0.5465 - acc: 0.7396 - 51ms/epoch - 3ms/step\n",
            "Epoch 131/200\n",
            "18/18 - 0s - loss: 0.5459 - acc: 0.7413 - 53ms/epoch - 3ms/step\n",
            "Epoch 132/200\n",
            "18/18 - 0s - loss: 0.5453 - acc: 0.7465 - 66ms/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "18/18 - 0s - loss: 0.5447 - acc: 0.7465 - 63ms/epoch - 3ms/step\n",
            "Epoch 134/200\n",
            "18/18 - 0s - loss: 0.5442 - acc: 0.7465 - 55ms/epoch - 3ms/step\n",
            "Epoch 135/200\n",
            "18/18 - 0s - loss: 0.5436 - acc: 0.7465 - 52ms/epoch - 3ms/step\n",
            "Epoch 136/200\n",
            "18/18 - 0s - loss: 0.5430 - acc: 0.7465 - 54ms/epoch - 3ms/step\n",
            "Epoch 137/200\n",
            "18/18 - 0s - loss: 0.5424 - acc: 0.7465 - 41ms/epoch - 2ms/step\n",
            "Epoch 138/200\n",
            "18/18 - 0s - loss: 0.5419 - acc: 0.7465 - 34ms/epoch - 2ms/step\n",
            "Epoch 139/200\n",
            "18/18 - 0s - loss: 0.5413 - acc: 0.7448 - 38ms/epoch - 2ms/step\n",
            "Epoch 140/200\n",
            "18/18 - 0s - loss: 0.5408 - acc: 0.7465 - 37ms/epoch - 2ms/step\n",
            "Epoch 141/200\n",
            "18/18 - 0s - loss: 0.5402 - acc: 0.7465 - 36ms/epoch - 2ms/step\n",
            "Epoch 142/200\n",
            "18/18 - 0s - loss: 0.5397 - acc: 0.7465 - 38ms/epoch - 2ms/step\n",
            "Epoch 143/200\n",
            "18/18 - 0s - loss: 0.5391 - acc: 0.7448 - 36ms/epoch - 2ms/step\n",
            "Epoch 144/200\n",
            "18/18 - 0s - loss: 0.5386 - acc: 0.7448 - 35ms/epoch - 2ms/step\n",
            "Epoch 145/200\n",
            "18/18 - 0s - loss: 0.5380 - acc: 0.7448 - 48ms/epoch - 3ms/step\n",
            "Epoch 146/200\n",
            "18/18 - 0s - loss: 0.5375 - acc: 0.7448 - 35ms/epoch - 2ms/step\n",
            "Epoch 147/200\n",
            "18/18 - 0s - loss: 0.5370 - acc: 0.7448 - 34ms/epoch - 2ms/step\n",
            "Epoch 148/200\n",
            "18/18 - 0s - loss: 0.5365 - acc: 0.7431 - 34ms/epoch - 2ms/step\n",
            "Epoch 149/200\n",
            "18/18 - 0s - loss: 0.5360 - acc: 0.7431 - 34ms/epoch - 2ms/step\n",
            "Epoch 150/200\n",
            "18/18 - 0s - loss: 0.5355 - acc: 0.7431 - 35ms/epoch - 2ms/step\n",
            "Epoch 151/200\n",
            "18/18 - 0s - loss: 0.5350 - acc: 0.7413 - 36ms/epoch - 2ms/step\n",
            "Epoch 152/200\n",
            "18/18 - 0s - loss: 0.5345 - acc: 0.7413 - 50ms/epoch - 3ms/step\n",
            "Epoch 153/200\n",
            "18/18 - 0s - loss: 0.5340 - acc: 0.7396 - 35ms/epoch - 2ms/step\n",
            "Epoch 154/200\n",
            "18/18 - 0s - loss: 0.5335 - acc: 0.7413 - 34ms/epoch - 2ms/step\n",
            "Epoch 155/200\n",
            "18/18 - 0s - loss: 0.5330 - acc: 0.7413 - 42ms/epoch - 2ms/step\n",
            "Epoch 156/200\n",
            "18/18 - 0s - loss: 0.5325 - acc: 0.7413 - 34ms/epoch - 2ms/step\n",
            "Epoch 157/200\n",
            "18/18 - 0s - loss: 0.5320 - acc: 0.7413 - 36ms/epoch - 2ms/step\n",
            "Epoch 158/200\n",
            "18/18 - 0s - loss: 0.5316 - acc: 0.7413 - 35ms/epoch - 2ms/step\n",
            "Epoch 159/200\n",
            "18/18 - 0s - loss: 0.5311 - acc: 0.7431 - 35ms/epoch - 2ms/step\n",
            "Epoch 160/200\n",
            "18/18 - 0s - loss: 0.5306 - acc: 0.7448 - 34ms/epoch - 2ms/step\n",
            "Epoch 161/200\n",
            "18/18 - 0s - loss: 0.5302 - acc: 0.7431 - 33ms/epoch - 2ms/step\n",
            "Epoch 162/200\n",
            "18/18 - 0s - loss: 0.5297 - acc: 0.7431 - 37ms/epoch - 2ms/step\n",
            "Epoch 163/200\n",
            "18/18 - 0s - loss: 0.5292 - acc: 0.7431 - 36ms/epoch - 2ms/step\n",
            "Epoch 164/200\n",
            "18/18 - 0s - loss: 0.5288 - acc: 0.7431 - 36ms/epoch - 2ms/step\n",
            "Epoch 165/200\n",
            "18/18 - 0s - loss: 0.5283 - acc: 0.7448 - 45ms/epoch - 3ms/step\n",
            "Epoch 166/200\n",
            "18/18 - 0s - loss: 0.5279 - acc: 0.7465 - 35ms/epoch - 2ms/step\n",
            "Epoch 167/200\n",
            "18/18 - 0s - loss: 0.5274 - acc: 0.7465 - 37ms/epoch - 2ms/step\n",
            "Epoch 168/200\n",
            "18/18 - 0s - loss: 0.5270 - acc: 0.7465 - 35ms/epoch - 2ms/step\n",
            "Epoch 169/200\n",
            "18/18 - 0s - loss: 0.5266 - acc: 0.7465 - 34ms/epoch - 2ms/step\n",
            "Epoch 170/200\n",
            "18/18 - 0s - loss: 0.5261 - acc: 0.7465 - 34ms/epoch - 2ms/step\n",
            "Epoch 171/200\n",
            "18/18 - 0s - loss: 0.5257 - acc: 0.7483 - 34ms/epoch - 2ms/step\n",
            "Epoch 172/200\n",
            "18/18 - 0s - loss: 0.5253 - acc: 0.7483 - 35ms/epoch - 2ms/step\n",
            "Epoch 173/200\n",
            "18/18 - 0s - loss: 0.5249 - acc: 0.7483 - 34ms/epoch - 2ms/step\n",
            "Epoch 174/200\n",
            "18/18 - 0s - loss: 0.5245 - acc: 0.7483 - 35ms/epoch - 2ms/step\n",
            "Epoch 175/200\n",
            "18/18 - 0s - loss: 0.5240 - acc: 0.7500 - 33ms/epoch - 2ms/step\n",
            "Epoch 176/200\n",
            "18/18 - 0s - loss: 0.5236 - acc: 0.7500 - 34ms/epoch - 2ms/step\n",
            "Epoch 177/200\n",
            "18/18 - 0s - loss: 0.5232 - acc: 0.7517 - 44ms/epoch - 2ms/step\n",
            "Epoch 178/200\n",
            "18/18 - 0s - loss: 0.5228 - acc: 0.7517 - 35ms/epoch - 2ms/step\n",
            "Epoch 179/200\n",
            "18/18 - 0s - loss: 0.5224 - acc: 0.7517 - 51ms/epoch - 3ms/step\n",
            "Epoch 180/200\n",
            "18/18 - 0s - loss: 0.5220 - acc: 0.7500 - 36ms/epoch - 2ms/step\n",
            "Epoch 181/200\n",
            "18/18 - 0s - loss: 0.5216 - acc: 0.7500 - 35ms/epoch - 2ms/step\n",
            "Epoch 182/200\n",
            "18/18 - 0s - loss: 0.5212 - acc: 0.7500 - 35ms/epoch - 2ms/step\n",
            "Epoch 183/200\n",
            "18/18 - 0s - loss: 0.5209 - acc: 0.7535 - 34ms/epoch - 2ms/step\n",
            "Epoch 184/200\n",
            "18/18 - 0s - loss: 0.5205 - acc: 0.7517 - 35ms/epoch - 2ms/step\n",
            "Epoch 185/200\n",
            "18/18 - 0s - loss: 0.5201 - acc: 0.7517 - 38ms/epoch - 2ms/step\n",
            "Epoch 186/200\n",
            "18/18 - 0s - loss: 0.5197 - acc: 0.7535 - 39ms/epoch - 2ms/step\n",
            "Epoch 187/200\n",
            "18/18 - 0s - loss: 0.5193 - acc: 0.7552 - 34ms/epoch - 2ms/step\n",
            "Epoch 188/200\n",
            "18/18 - 0s - loss: 0.5190 - acc: 0.7552 - 34ms/epoch - 2ms/step\n",
            "Epoch 189/200\n",
            "18/18 - 0s - loss: 0.5186 - acc: 0.7535 - 35ms/epoch - 2ms/step\n",
            "Epoch 190/200\n",
            "18/18 - 0s - loss: 0.5182 - acc: 0.7535 - 35ms/epoch - 2ms/step\n",
            "Epoch 191/200\n",
            "18/18 - 0s - loss: 0.5179 - acc: 0.7552 - 34ms/epoch - 2ms/step\n",
            "Epoch 192/200\n",
            "18/18 - 0s - loss: 0.5175 - acc: 0.7552 - 37ms/epoch - 2ms/step\n",
            "Epoch 193/200\n",
            "18/18 - 0s - loss: 0.5171 - acc: 0.7552 - 36ms/epoch - 2ms/step\n",
            "Epoch 194/200\n",
            "18/18 - 0s - loss: 0.5168 - acc: 0.7552 - 34ms/epoch - 2ms/step\n",
            "Epoch 195/200\n",
            "18/18 - 0s - loss: 0.5164 - acc: 0.7569 - 35ms/epoch - 2ms/step\n",
            "Epoch 196/200\n",
            "18/18 - 0s - loss: 0.5161 - acc: 0.7587 - 33ms/epoch - 2ms/step\n",
            "Epoch 197/200\n",
            "18/18 - 0s - loss: 0.5157 - acc: 0.7587 - 35ms/epoch - 2ms/step\n",
            "Epoch 198/200\n",
            "18/18 - 0s - loss: 0.5154 - acc: 0.7587 - 34ms/epoch - 2ms/step\n",
            "Epoch 199/200\n",
            "18/18 - 0s - loss: 0.5151 - acc: 0.7587 - 35ms/epoch - 2ms/step\n",
            "Epoch 200/200\n",
            "18/18 - 0s - loss: 0.5147 - acc: 0.7604 - 36ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gimA-EKPwZ_A",
        "outputId": "dadf0f02-64ca-4aeb-a872-fefaf3231c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5622 - acc: 0.7240\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5622296929359436, 0.7239583134651184]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model.predict(x_test, verbose=0)"
      ],
      "metadata": {
        "id": "lw1TsFrg2ptY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_test = (p > 0.5)\n",
        "print('acc:', np.mean(p_test == y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zOiuA_J9fHc",
        "outputId": "75313a04-8a49-4298-8311-ac77df8addcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 0.7239583333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.int32([1,2,3]) + 1\n",
        "a = np.arange(10)\n",
        "a + 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R3xfLgkB28n",
        "outputId": "e552ad71-df75-424b-b3b4-ee1e932cf889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# numpy"
      ],
      "metadata": {
        "id": "o_bqTrZKC4T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.arange(6)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKk-e6HzBoES",
        "outputId": "f35d619a-516b-4282-e4b1-e383838684f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a+1)  # broadcast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jv86t9yDYfd",
        "outputId": "a7feed97-567a-4d7c-ed4a-0faa1352fddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a+a)  # vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8tZyr0ODcqh",
        "outputId": "4227fa13-5cc4-486f-d577-ea002136ef9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  2  4  6  8 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sin(a))    # universal function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybry4I7lDkdt",
        "outputId": "eeb2c7de-bb77-4b6a-852d-a521e410f903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.          0.84147098  0.90929743  0.14112001 -0.7568025  -0.95892427]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sin([0,1,2,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAT3m9_FDuyR",
        "outputId": "3829f4fe-5e63-4408-81df-f2a232235cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.84147098, 0.90929743, 0.14112001])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3]"
      ],
      "metadata": {
        "id": "1asvWae3EBvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a+ a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7iu1sczENI2",
        "outputId": "15b851a4-1caa-452a-9bce-30ee0c89a5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_3_1_softmax_regression.py"
      ],
      "metadata": {
        "id": "nrcA9sykExJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   y         x.          w\n",
        "# (7, 2)  = (3, 5) * (5, 2) > weight 개수와 feature 개수가 같아야 한다. \n",
        "# (7, 1)  = (7, 2) * (2, 1)"
      ],
      "metadata": {
        "id": "jvAwkcRJENvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "red, green, blue = 0, 1, 2 로 매핑하면 안된다.\n",
        "\n",
        "왜냐하면 logistic regression 은 0, 1로만 구분하기 때문이다.\n",
        "\n",
        "따라서 \n",
        "- red = 1, 0, 0\n",
        "- green = 0, 1, 0\n",
        "- blue = 0, 0, 1\n",
        "\n",
        "로 변환해야 함, = one-hot encoding"
      ],
      "metadata": {
        "id": "EV1Q3t4FJcmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[1, 2],  # C\n",
        "        [2, 1],\n",
        "        [4, 5],     # B\n",
        "        [5, 4],\n",
        "        [8, 9],     # A\n",
        "        [9, 8]]\n",
        "y = [[0, 0, 1],\n",
        "    [0, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [0, 1, 0],\n",
        "    [1, 0, 0],\n",
        "    [1, 0, 0]]"
      ],
      "metadata": {
        "id": "ctQ9ieOfLOdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_regression_onehot(x, y):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=[2]))\n",
        "    # (6, 3) = (6, 2) @ (2, 3)  \n",
        "    # -> weight 변수 갯수는 6개인데, 왜 model parameter 갯수는 9개? -> bias 3개가 추가되기 때문\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    model.summary()    \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
        "                loss=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics='acc')\n",
        "\n",
        "    model.fit(x, y, epochs=300, verbose=2)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "XctsYXHTHroO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = softmax_regression_onehot(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgOOOcqZLdcu",
        "outputId": "ed9969ab-f236-4b7b-ab7f-64387775be38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "1/1 - 0s - loss: 5.8010 - acc: 0.3333 - 478ms/epoch - 478ms/step\n",
            "Epoch 2/300\n",
            "1/1 - 0s - loss: 5.2708 - acc: 0.3333 - 15ms/epoch - 15ms/step\n",
            "Epoch 3/300\n",
            "1/1 - 0s - loss: 4.7625 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 4/300\n",
            "1/1 - 0s - loss: 4.2900 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 5/300\n",
            "1/1 - 0s - loss: 3.8766 - acc: 0.1667 - 8ms/epoch - 8ms/step\n",
            "Epoch 6/300\n",
            "1/1 - 0s - loss: 3.5506 - acc: 0.1667 - 7ms/epoch - 7ms/step\n",
            "Epoch 7/300\n",
            "1/1 - 0s - loss: 3.3235 - acc: 0.1667 - 7ms/epoch - 7ms/step\n",
            "Epoch 8/300\n",
            "1/1 - 0s - loss: 3.1727 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 9/300\n",
            "1/1 - 0s - loss: 3.0647 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 10/300\n",
            "1/1 - 0s - loss: 2.9773 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 11/300\n",
            "1/1 - 0s - loss: 2.8997 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 12/300\n",
            "1/1 - 0s - loss: 2.8270 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 13/300\n",
            "1/1 - 0s - loss: 2.7569 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 14/300\n",
            "1/1 - 0s - loss: 2.6883 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 15/300\n",
            "1/1 - 0s - loss: 2.6207 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 16/300\n",
            "1/1 - 0s - loss: 2.5537 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 17/300\n",
            "1/1 - 0s - loss: 2.4871 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 18/300\n",
            "1/1 - 0s - loss: 2.4210 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 19/300\n",
            "1/1 - 0s - loss: 2.3553 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 20/300\n",
            "1/1 - 0s - loss: 2.2899 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 21/300\n",
            "1/1 - 0s - loss: 2.2250 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 22/300\n",
            "1/1 - 0s - loss: 2.1604 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 23/300\n",
            "1/1 - 0s - loss: 2.0963 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 24/300\n",
            "1/1 - 0s - loss: 2.0327 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 25/300\n",
            "1/1 - 0s - loss: 1.9696 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 26/300\n",
            "1/1 - 0s - loss: 1.9070 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 27/300\n",
            "1/1 - 0s - loss: 1.8452 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 28/300\n",
            "1/1 - 0s - loss: 1.7840 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 29/300\n",
            "1/1 - 0s - loss: 1.7237 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 30/300\n",
            "1/1 - 0s - loss: 1.6643 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 31/300\n",
            "1/1 - 0s - loss: 1.6060 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 32/300\n",
            "1/1 - 0s - loss: 1.5488 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 33/300\n",
            "1/1 - 0s - loss: 1.4931 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 34/300\n",
            "1/1 - 0s - loss: 1.4388 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 35/300\n",
            "1/1 - 0s - loss: 1.3864 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/300\n",
            "1/1 - 0s - loss: 1.3360 - acc: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 37/300\n",
            "1/1 - 0s - loss: 1.2879 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 38/300\n",
            "1/1 - 0s - loss: 1.2425 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 39/300\n",
            "1/1 - 0s - loss: 1.2001 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 40/300\n",
            "1/1 - 0s - loss: 1.1610 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 41/300\n",
            "1/1 - 0s - loss: 1.1255 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 42/300\n",
            "1/1 - 0s - loss: 1.0938 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 43/300\n",
            "1/1 - 0s - loss: 1.0662 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 44/300\n",
            "1/1 - 0s - loss: 1.0425 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 45/300\n",
            "1/1 - 0s - loss: 1.0227 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 46/300\n",
            "1/1 - 0s - loss: 1.0065 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 47/300\n",
            "1/1 - 0s - loss: 0.9934 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 48/300\n",
            "1/1 - 0s - loss: 0.9830 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 49/300\n",
            "1/1 - 0s - loss: 0.9748 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 50/300\n",
            "1/1 - 0s - loss: 0.9684 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 51/300\n",
            "1/1 - 0s - loss: 0.9633 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/300\n",
            "1/1 - 0s - loss: 0.9593 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 53/300\n",
            "1/1 - 0s - loss: 0.9561 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 54/300\n",
            "1/1 - 0s - loss: 0.9534 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 55/300\n",
            "1/1 - 0s - loss: 0.9512 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 56/300\n",
            "1/1 - 0s - loss: 0.9493 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 57/300\n",
            "1/1 - 0s - loss: 0.9477 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 58/300\n",
            "1/1 - 0s - loss: 0.9462 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 59/300\n",
            "1/1 - 0s - loss: 0.9450 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 60/300\n",
            "1/1 - 0s - loss: 0.9438 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 61/300\n",
            "1/1 - 0s - loss: 0.9427 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 62/300\n",
            "1/1 - 0s - loss: 0.9417 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 63/300\n",
            "1/1 - 0s - loss: 0.9407 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 64/300\n",
            "1/1 - 0s - loss: 0.9399 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 65/300\n",
            "1/1 - 0s - loss: 0.9390 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 66/300\n",
            "1/1 - 0s - loss: 0.9382 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 67/300\n",
            "1/1 - 0s - loss: 0.9374 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 68/300\n",
            "1/1 - 0s - loss: 0.9366 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 69/300\n",
            "1/1 - 0s - loss: 0.9359 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 70/300\n",
            "1/1 - 0s - loss: 0.9351 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 71/300\n",
            "1/1 - 0s - loss: 0.9344 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 72/300\n",
            "1/1 - 0s - loss: 0.9337 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 73/300\n",
            "1/1 - 0s - loss: 0.9330 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 74/300\n",
            "1/1 - 0s - loss: 0.9324 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 75/300\n",
            "1/1 - 0s - loss: 0.9317 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 76/300\n",
            "1/1 - 0s - loss: 0.9310 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 77/300\n",
            "1/1 - 0s - loss: 0.9303 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 78/300\n",
            "1/1 - 0s - loss: 0.9297 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 79/300\n",
            "1/1 - 0s - loss: 0.9290 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 80/300\n",
            "1/1 - 0s - loss: 0.9284 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 81/300\n",
            "1/1 - 0s - loss: 0.9277 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 82/300\n",
            "1/1 - 0s - loss: 0.9271 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 83/300\n",
            "1/1 - 0s - loss: 0.9265 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 84/300\n",
            "1/1 - 0s - loss: 0.9258 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 85/300\n",
            "1/1 - 0s - loss: 0.9252 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 86/300\n",
            "1/1 - 0s - loss: 0.9246 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 87/300\n",
            "1/1 - 0s - loss: 0.9239 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 88/300\n",
            "1/1 - 0s - loss: 0.9233 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 89/300\n",
            "1/1 - 0s - loss: 0.9227 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 90/300\n",
            "1/1 - 0s - loss: 0.9220 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 91/300\n",
            "1/1 - 0s - loss: 0.9214 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 92/300\n",
            "1/1 - 0s - loss: 0.9208 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 93/300\n",
            "1/1 - 0s - loss: 0.9202 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 94/300\n",
            "1/1 - 0s - loss: 0.9196 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 95/300\n",
            "1/1 - 0s - loss: 0.9189 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 96/300\n",
            "1/1 - 0s - loss: 0.9183 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 97/300\n",
            "1/1 - 0s - loss: 0.9177 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 98/300\n",
            "1/1 - 0s - loss: 0.9171 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 99/300\n",
            "1/1 - 0s - loss: 0.9165 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 100/300\n",
            "1/1 - 0s - loss: 0.9159 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 101/300\n",
            "1/1 - 0s - loss: 0.9153 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 102/300\n",
            "1/1 - 0s - loss: 0.9146 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 103/300\n",
            "1/1 - 0s - loss: 0.9140 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 104/300\n",
            "1/1 - 0s - loss: 0.9134 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 105/300\n",
            "1/1 - 0s - loss: 0.9128 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 106/300\n",
            "1/1 - 0s - loss: 0.9122 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 107/300\n",
            "1/1 - 0s - loss: 0.9116 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 108/300\n",
            "1/1 - 0s - loss: 0.9110 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 109/300\n",
            "1/1 - 0s - loss: 0.9104 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 110/300\n",
            "1/1 - 0s - loss: 0.9098 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 111/300\n",
            "1/1 - 0s - loss: 0.9092 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 112/300\n",
            "1/1 - 0s - loss: 0.9086 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 113/300\n",
            "1/1 - 0s - loss: 0.9080 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 114/300\n",
            "1/1 - 0s - loss: 0.9074 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 115/300\n",
            "1/1 - 0s - loss: 0.9068 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 116/300\n",
            "1/1 - 0s - loss: 0.9062 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 117/300\n",
            "1/1 - 0s - loss: 0.9056 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 118/300\n",
            "1/1 - 0s - loss: 0.9050 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 119/300\n",
            "1/1 - 0s - loss: 0.9044 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 120/300\n",
            "1/1 - 0s - loss: 0.9038 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 121/300\n",
            "1/1 - 0s - loss: 0.9032 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 122/300\n",
            "1/1 - 0s - loss: 0.9026 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 123/300\n",
            "1/1 - 0s - loss: 0.9020 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 124/300\n",
            "1/1 - 0s - loss: 0.9014 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 125/300\n",
            "1/1 - 0s - loss: 0.9008 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 126/300\n",
            "1/1 - 0s - loss: 0.9002 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 127/300\n",
            "1/1 - 0s - loss: 0.8996 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 128/300\n",
            "1/1 - 0s - loss: 0.8990 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 129/300\n",
            "1/1 - 0s - loss: 0.8984 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 130/300\n",
            "1/1 - 0s - loss: 0.8978 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 131/300\n",
            "1/1 - 0s - loss: 0.8973 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 132/300\n",
            "1/1 - 0s - loss: 0.8967 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 133/300\n",
            "1/1 - 0s - loss: 0.8961 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 134/300\n",
            "1/1 - 0s - loss: 0.8955 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 135/300\n",
            "1/1 - 0s - loss: 0.8949 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 136/300\n",
            "1/1 - 0s - loss: 0.8943 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 137/300\n",
            "1/1 - 0s - loss: 0.8937 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 138/300\n",
            "1/1 - 0s - loss: 0.8932 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 139/300\n",
            "1/1 - 0s - loss: 0.8926 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 140/300\n",
            "1/1 - 0s - loss: 0.8920 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 141/300\n",
            "1/1 - 0s - loss: 0.8914 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 142/300\n",
            "1/1 - 0s - loss: 0.8908 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 143/300\n",
            "1/1 - 0s - loss: 0.8903 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 144/300\n",
            "1/1 - 0s - loss: 0.8897 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 145/300\n",
            "1/1 - 0s - loss: 0.8891 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 146/300\n",
            "1/1 - 0s - loss: 0.8885 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 147/300\n",
            "1/1 - 0s - loss: 0.8880 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 148/300\n",
            "1/1 - 0s - loss: 0.8874 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 149/300\n",
            "1/1 - 0s - loss: 0.8868 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 150/300\n",
            "1/1 - 0s - loss: 0.8862 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 151/300\n",
            "1/1 - 0s - loss: 0.8857 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 152/300\n",
            "1/1 - 0s - loss: 0.8851 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 153/300\n",
            "1/1 - 0s - loss: 0.8845 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 154/300\n",
            "1/1 - 0s - loss: 0.8839 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 155/300\n",
            "1/1 - 0s - loss: 0.8834 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 156/300\n",
            "1/1 - 0s - loss: 0.8828 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 157/300\n",
            "1/1 - 0s - loss: 0.8822 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 158/300\n",
            "1/1 - 0s - loss: 0.8817 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 159/300\n",
            "1/1 - 0s - loss: 0.8811 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 160/300\n",
            "1/1 - 0s - loss: 0.8805 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 161/300\n",
            "1/1 - 0s - loss: 0.8800 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 162/300\n",
            "1/1 - 0s - loss: 0.8794 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 163/300\n",
            "1/1 - 0s - loss: 0.8789 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 164/300\n",
            "1/1 - 0s - loss: 0.8783 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 165/300\n",
            "1/1 - 0s - loss: 0.8777 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 166/300\n",
            "1/1 - 0s - loss: 0.8772 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 167/300\n",
            "1/1 - 0s - loss: 0.8766 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 168/300\n",
            "1/1 - 0s - loss: 0.8760 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 169/300\n",
            "1/1 - 0s - loss: 0.8755 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 170/300\n",
            "1/1 - 0s - loss: 0.8749 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 171/300\n",
            "1/1 - 0s - loss: 0.8744 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 172/300\n",
            "1/1 - 0s - loss: 0.8738 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 173/300\n",
            "1/1 - 0s - loss: 0.8733 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 174/300\n",
            "1/1 - 0s - loss: 0.8727 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 175/300\n",
            "1/1 - 0s - loss: 0.8721 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 176/300\n",
            "1/1 - 0s - loss: 0.8716 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 177/300\n",
            "1/1 - 0s - loss: 0.8710 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 178/300\n",
            "1/1 - 0s - loss: 0.8705 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 179/300\n",
            "1/1 - 0s - loss: 0.8699 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 180/300\n",
            "1/1 - 0s - loss: 0.8694 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 181/300\n",
            "1/1 - 0s - loss: 0.8688 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 182/300\n",
            "1/1 - 0s - loss: 0.8683 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 183/300\n",
            "1/1 - 0s - loss: 0.8677 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 184/300\n",
            "1/1 - 0s - loss: 0.8672 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 185/300\n",
            "1/1 - 0s - loss: 0.8666 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 186/300\n",
            "1/1 - 0s - loss: 0.8661 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 187/300\n",
            "1/1 - 0s - loss: 0.8655 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 188/300\n",
            "1/1 - 0s - loss: 0.8650 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 189/300\n",
            "1/1 - 0s - loss: 0.8645 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 190/300\n",
            "1/1 - 0s - loss: 0.8639 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 191/300\n",
            "1/1 - 0s - loss: 0.8634 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 192/300\n",
            "1/1 - 0s - loss: 0.8628 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 193/300\n",
            "1/1 - 0s - loss: 0.8623 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 194/300\n",
            "1/1 - 0s - loss: 0.8617 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 195/300\n",
            "1/1 - 0s - loss: 0.8612 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 196/300\n",
            "1/1 - 0s - loss: 0.8607 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 197/300\n",
            "1/1 - 0s - loss: 0.8601 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 198/300\n",
            "1/1 - 0s - loss: 0.8596 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 199/300\n",
            "1/1 - 0s - loss: 0.8590 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 200/300\n",
            "1/1 - 0s - loss: 0.8585 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 201/300\n",
            "1/1 - 0s - loss: 0.8580 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 202/300\n",
            "1/1 - 0s - loss: 0.8574 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 203/300\n",
            "1/1 - 0s - loss: 0.8569 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 204/300\n",
            "1/1 - 0s - loss: 0.8564 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 205/300\n",
            "1/1 - 0s - loss: 0.8558 - acc: 0.5000 - 24ms/epoch - 24ms/step\n",
            "Epoch 206/300\n",
            "1/1 - 0s - loss: 0.8553 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 207/300\n",
            "1/1 - 0s - loss: 0.8548 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 208/300\n",
            "1/1 - 0s - loss: 0.8542 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 209/300\n",
            "1/1 - 0s - loss: 0.8537 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 210/300\n",
            "1/1 - 0s - loss: 0.8532 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 211/300\n",
            "1/1 - 0s - loss: 0.8527 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 212/300\n",
            "1/1 - 0s - loss: 0.8521 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 213/300\n",
            "1/1 - 0s - loss: 0.8516 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 214/300\n",
            "1/1 - 0s - loss: 0.8511 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 215/300\n",
            "1/1 - 0s - loss: 0.8505 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 216/300\n",
            "1/1 - 0s - loss: 0.8500 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 217/300\n",
            "1/1 - 0s - loss: 0.8495 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 218/300\n",
            "1/1 - 0s - loss: 0.8490 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 219/300\n",
            "1/1 - 0s - loss: 0.8484 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 220/300\n",
            "1/1 - 0s - loss: 0.8479 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 221/300\n",
            "1/1 - 0s - loss: 0.8474 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 222/300\n",
            "1/1 - 0s - loss: 0.8469 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 223/300\n",
            "1/1 - 0s - loss: 0.8464 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 224/300\n",
            "1/1 - 0s - loss: 0.8458 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 225/300\n",
            "1/1 - 0s - loss: 0.8453 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 226/300\n",
            "1/1 - 0s - loss: 0.8448 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 227/300\n",
            "1/1 - 0s - loss: 0.8443 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 228/300\n",
            "1/1 - 0s - loss: 0.8438 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 229/300\n",
            "1/1 - 0s - loss: 0.8432 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 230/300\n",
            "1/1 - 0s - loss: 0.8427 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 231/300\n",
            "1/1 - 0s - loss: 0.8422 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 232/300\n",
            "1/1 - 0s - loss: 0.8417 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 233/300\n",
            "1/1 - 0s - loss: 0.8412 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 234/300\n",
            "1/1 - 0s - loss: 0.8407 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 235/300\n",
            "1/1 - 0s - loss: 0.8402 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 236/300\n",
            "1/1 - 0s - loss: 0.8396 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 237/300\n",
            "1/1 - 0s - loss: 0.8391 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 238/300\n",
            "1/1 - 0s - loss: 0.8386 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 239/300\n",
            "1/1 - 0s - loss: 0.8381 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 240/300\n",
            "1/1 - 0s - loss: 0.8376 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 241/300\n",
            "1/1 - 0s - loss: 0.8371 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 242/300\n",
            "1/1 - 0s - loss: 0.8366 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 243/300\n",
            "1/1 - 0s - loss: 0.8361 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 244/300\n",
            "1/1 - 0s - loss: 0.8356 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 245/300\n",
            "1/1 - 0s - loss: 0.8351 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 246/300\n",
            "1/1 - 0s - loss: 0.8346 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 247/300\n",
            "1/1 - 0s - loss: 0.8341 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 248/300\n",
            "1/1 - 0s - loss: 0.8335 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 249/300\n",
            "1/1 - 0s - loss: 0.8330 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 250/300\n",
            "1/1 - 0s - loss: 0.8325 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 251/300\n",
            "1/1 - 0s - loss: 0.8320 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 252/300\n",
            "1/1 - 0s - loss: 0.8315 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 253/300\n",
            "1/1 - 0s - loss: 0.8310 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 254/300\n",
            "1/1 - 0s - loss: 0.8305 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 255/300\n",
            "1/1 - 0s - loss: 0.8300 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 256/300\n",
            "1/1 - 0s - loss: 0.8295 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 257/300\n",
            "1/1 - 0s - loss: 0.8290 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 258/300\n",
            "1/1 - 0s - loss: 0.8285 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 259/300\n",
            "1/1 - 0s - loss: 0.8280 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 260/300\n",
            "1/1 - 0s - loss: 0.8275 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 261/300\n",
            "1/1 - 0s - loss: 0.8270 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 262/300\n",
            "1/1 - 0s - loss: 0.8266 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 263/300\n",
            "1/1 - 0s - loss: 0.8261 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 264/300\n",
            "1/1 - 0s - loss: 0.8256 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 265/300\n",
            "1/1 - 0s - loss: 0.8251 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 266/300\n",
            "1/1 - 0s - loss: 0.8246 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 267/300\n",
            "1/1 - 0s - loss: 0.8241 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 268/300\n",
            "1/1 - 0s - loss: 0.8236 - acc: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 269/300\n",
            "1/1 - 0s - loss: 0.8231 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 270/300\n",
            "1/1 - 0s - loss: 0.8226 - acc: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 271/300\n",
            "1/1 - 0s - loss: 0.8221 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 272/300\n",
            "1/1 - 0s - loss: 0.8216 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 273/300\n",
            "1/1 - 0s - loss: 0.8211 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 274/300\n",
            "1/1 - 0s - loss: 0.8207 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 275/300\n",
            "1/1 - 0s - loss: 0.8202 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 276/300\n",
            "1/1 - 0s - loss: 0.8197 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 277/300\n",
            "1/1 - 0s - loss: 0.8192 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 278/300\n",
            "1/1 - 0s - loss: 0.8187 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 279/300\n",
            "1/1 - 0s - loss: 0.8182 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 280/300\n",
            "1/1 - 0s - loss: 0.8177 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 281/300\n",
            "1/1 - 0s - loss: 0.8173 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 282/300\n",
            "1/1 - 0s - loss: 0.8168 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 283/300\n",
            "1/1 - 0s - loss: 0.8163 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 284/300\n",
            "1/1 - 0s - loss: 0.8158 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 285/300\n",
            "1/1 - 0s - loss: 0.8153 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 286/300\n",
            "1/1 - 0s - loss: 0.8149 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 287/300\n",
            "1/1 - 0s - loss: 0.8144 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 288/300\n",
            "1/1 - 0s - loss: 0.8139 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 289/300\n",
            "1/1 - 0s - loss: 0.8134 - acc: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 290/300\n",
            "1/1 - 0s - loss: 0.8129 - acc: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 291/300\n",
            "1/1 - 0s - loss: 0.8125 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 292/300\n",
            "1/1 - 0s - loss: 0.8120 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 293/300\n",
            "1/1 - 0s - loss: 0.8115 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 294/300\n",
            "1/1 - 0s - loss: 0.8110 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 295/300\n",
            "1/1 - 0s - loss: 0.8106 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 296/300\n",
            "1/1 - 0s - loss: 0.8101 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 297/300\n",
            "1/1 - 0s - loss: 0.8096 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 298/300\n",
            "1/1 - 0s - loss: 0.8091 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 299/300\n",
            "1/1 - 0s - loss: 0.8087 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 300/300\n",
            "1/1 - 0s - loss: 0.8082 - acc: 0.5000 - 9ms/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model.predict(x, verbose=0)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fcWBrwCMVNg",
        "outputId": "422199bb-584b-4dd8-e497-1ce2c805a1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.24458332 0.3409932  0.4144235 ]\n",
            " [0.2975201  0.4264332  0.2760467 ]\n",
            " [0.44949892 0.35469976 0.19580129]\n",
            " [0.48786107 0.39577138 0.11636752]\n",
            " [0.69413066 0.25644353 0.04942586]\n",
            " [0.70482063 0.26769787 0.02748148]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_arg = np.argmax(p, axis=1)\n",
        "p_arg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNi8WtcBQcFq",
        "outputId": "b4c71d28-741f-4ffb-d80f-3780f64a40c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_arg = np.argmax(y, axis=1)\n",
        "y_arg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfkWB0fER5BY",
        "outputId": "8b46003e-6620-4509-f667-82a7da014f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(p_arg == y_arg)\n",
        "print('acc: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9ipWykuSKck",
        "outputId": "7526f437-b258-4e42-a27c-a7c1665d88fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실제 사용코드"
      ],
      "metadata": {
        "id": "xAFhXskHS-iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   y         x.          w\n",
        "# (3, 2)  = (3, 5) * (5, 2) > weight 개수와 feature 개수가 같아야 한다. \n",
        "# (7, 1)  = (7, 2) * (2, 1)"
      ],
      "metadata": {
        "id": "TsS4QV8zTNKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "red, green, blue = 0, 1, 2 로 매핑하면 안된다.\n",
        "\n",
        "왜냐하면 logistic regression 은 0, 1로만 구분하기 때문이다.\n",
        "\n",
        "따라서 \n",
        "- red = 1, 0, 0\n",
        "- green = 0, 1, 0\n",
        "- blue = 0, 0, 1\n",
        "\n",
        "로 변환해야 함, = one-hot encoding"
      ],
      "metadata": {
        "id": "i7LhWG9yTNKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_regression_sparse(x, y):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=[2]))\n",
        "    # (6, 3) = (6, 2) @ (2, 3)  \n",
        "    # -> weight 변수 갯수는 6개인데, 왜 model parameter 갯수는 9개? -> bias 3개가 추가되기 때문\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    model.summary()    \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics='acc')\n",
        "\n",
        "    model.fit(x, y, epochs=300, verbose=2)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "DtbHtvpQTNKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[1, 2],  # C\n",
        "        [2, 1],\n",
        "        [4, 5],     # B\n",
        "        [5, 4],\n",
        "        [8, 9],     # A\n",
        "        [9, 8]]\n",
        "y = [2,\n",
        "     2,\n",
        "     1,\n",
        "     1,\n",
        "     0,\n",
        "     0]"
      ],
      "metadata": {
        "id": "-eQXbai6TNKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = softmax_regression_sparse(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b19eb0-ca67-4450-cefc-3644017f9554",
        "id": "rhZvrEMDTNKm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "1/1 - 0s - loss: 6.2898 - acc: 0.3333 - 241ms/epoch - 241ms/step\n",
            "Epoch 2/300\n",
            "1/1 - 0s - loss: 5.7412 - acc: 0.3333 - 9ms/epoch - 9ms/step\n",
            "Epoch 3/300\n",
            "1/1 - 0s - loss: 5.2014 - acc: 0.3333 - 9ms/epoch - 9ms/step\n",
            "Epoch 4/300\n",
            "1/1 - 0s - loss: 4.6732 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 5/300\n",
            "1/1 - 0s - loss: 4.1611 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 6/300\n",
            "1/1 - 0s - loss: 3.6722 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 7/300\n",
            "1/1 - 0s - loss: 3.2165 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 8/300\n",
            "1/1 - 0s - loss: 2.8069 - acc: 0.1667 - 15ms/epoch - 15ms/step\n",
            "Epoch 9/300\n",
            "1/1 - 0s - loss: 2.4540 - acc: 0.1667 - 9ms/epoch - 9ms/step\n",
            "Epoch 10/300\n",
            "1/1 - 0s - loss: 2.1594 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 11/300\n",
            "1/1 - 0s - loss: 1.9141 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 12/300\n",
            "1/1 - 0s - loss: 1.7068 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 13/300\n",
            "1/1 - 0s - loss: 1.5316 - acc: 0.1667 - 7ms/epoch - 7ms/step\n",
            "Epoch 14/300\n",
            "1/1 - 0s - loss: 1.3873 - acc: 0.1667 - 8ms/epoch - 8ms/step\n",
            "Epoch 15/300\n",
            "1/1 - 0s - loss: 1.2747 - acc: 0.1667 - 7ms/epoch - 7ms/step\n",
            "Epoch 16/300\n",
            "1/1 - 0s - loss: 1.1923 - acc: 0.3333 - 10ms/epoch - 10ms/step\n",
            "Epoch 17/300\n",
            "1/1 - 0s - loss: 1.1357 - acc: 0.3333 - 9ms/epoch - 9ms/step\n",
            "Epoch 18/300\n",
            "1/1 - 0s - loss: 1.0983 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 19/300\n",
            "1/1 - 0s - loss: 1.0740 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 20/300\n",
            "1/1 - 0s - loss: 1.0583 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 21/300\n",
            "1/1 - 0s - loss: 1.0479 - acc: 0.3333 - 8ms/epoch - 8ms/step\n",
            "Epoch 22/300\n",
            "1/1 - 0s - loss: 1.0407 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 23/300\n",
            "1/1 - 0s - loss: 1.0357 - acc: 0.3333 - 7ms/epoch - 7ms/step\n",
            "Epoch 24/300\n",
            "1/1 - 0s - loss: 1.0319 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 25/300\n",
            "1/1 - 0s - loss: 1.0290 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 26/300\n",
            "1/1 - 0s - loss: 1.0266 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 27/300\n",
            "1/1 - 0s - loss: 1.0246 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 28/300\n",
            "1/1 - 0s - loss: 1.0228 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 29/300\n",
            "1/1 - 0s - loss: 1.0213 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 30/300\n",
            "1/1 - 0s - loss: 1.0199 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/300\n",
            "1/1 - 0s - loss: 1.0185 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 32/300\n",
            "1/1 - 0s - loss: 1.0173 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 33/300\n",
            "1/1 - 0s - loss: 1.0161 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 34/300\n",
            "1/1 - 0s - loss: 1.0150 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 35/300\n",
            "1/1 - 0s - loss: 1.0139 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/300\n",
            "1/1 - 0s - loss: 1.0129 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 37/300\n",
            "1/1 - 0s - loss: 1.0118 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 38/300\n",
            "1/1 - 0s - loss: 1.0108 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 39/300\n",
            "1/1 - 0s - loss: 1.0099 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 40/300\n",
            "1/1 - 0s - loss: 1.0089 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 41/300\n",
            "1/1 - 0s - loss: 1.0079 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 42/300\n",
            "1/1 - 0s - loss: 1.0070 - acc: 0.5000 - 6ms/epoch - 6ms/step\n",
            "Epoch 43/300\n",
            "1/1 - 0s - loss: 1.0061 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 44/300\n",
            "1/1 - 0s - loss: 1.0052 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 45/300\n",
            "1/1 - 0s - loss: 1.0042 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 46/300\n",
            "1/1 - 0s - loss: 1.0033 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 47/300\n",
            "1/1 - 0s - loss: 1.0024 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 48/300\n",
            "1/1 - 0s - loss: 1.0015 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 49/300\n",
            "1/1 - 0s - loss: 1.0007 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 50/300\n",
            "1/1 - 0s - loss: 0.9998 - acc: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 51/300\n",
            "1/1 - 0s - loss: 0.9989 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/300\n",
            "1/1 - 0s - loss: 0.9980 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 53/300\n",
            "1/1 - 0s - loss: 0.9971 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 54/300\n",
            "1/1 - 0s - loss: 0.9963 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 55/300\n",
            "1/1 - 0s - loss: 0.9954 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 56/300\n",
            "1/1 - 0s - loss: 0.9945 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 57/300\n",
            "1/1 - 0s - loss: 0.9937 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 58/300\n",
            "1/1 - 0s - loss: 0.9928 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 59/300\n",
            "1/1 - 0s - loss: 0.9919 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 60/300\n",
            "1/1 - 0s - loss: 0.9911 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 61/300\n",
            "1/1 - 0s - loss: 0.9902 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 62/300\n",
            "1/1 - 0s - loss: 0.9894 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 63/300\n",
            "1/1 - 0s - loss: 0.9885 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 64/300\n",
            "1/1 - 0s - loss: 0.9877 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 65/300\n",
            "1/1 - 0s - loss: 0.9868 - acc: 0.5000 - 6ms/epoch - 6ms/step\n",
            "Epoch 66/300\n",
            "1/1 - 0s - loss: 0.9860 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 67/300\n",
            "1/1 - 0s - loss: 0.9852 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 68/300\n",
            "1/1 - 0s - loss: 0.9843 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 69/300\n",
            "1/1 - 0s - loss: 0.9835 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 70/300\n",
            "1/1 - 0s - loss: 0.9826 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 71/300\n",
            "1/1 - 0s - loss: 0.9818 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 72/300\n",
            "1/1 - 0s - loss: 0.9810 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 73/300\n",
            "1/1 - 0s - loss: 0.9801 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 74/300\n",
            "1/1 - 0s - loss: 0.9793 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 75/300\n",
            "1/1 - 0s - loss: 0.9785 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 76/300\n",
            "1/1 - 0s - loss: 0.9776 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 77/300\n",
            "1/1 - 0s - loss: 0.9768 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 78/300\n",
            "1/1 - 0s - loss: 0.9760 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 79/300\n",
            "1/1 - 0s - loss: 0.9752 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 80/300\n",
            "1/1 - 0s - loss: 0.9744 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 81/300\n",
            "1/1 - 0s - loss: 0.9735 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 82/300\n",
            "1/1 - 0s - loss: 0.9727 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 83/300\n",
            "1/1 - 0s - loss: 0.9719 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 84/300\n",
            "1/1 - 0s - loss: 0.9711 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 85/300\n",
            "1/1 - 0s - loss: 0.9703 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 86/300\n",
            "1/1 - 0s - loss: 0.9695 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 87/300\n",
            "1/1 - 0s - loss: 0.9687 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 88/300\n",
            "1/1 - 0s - loss: 0.9678 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 89/300\n",
            "1/1 - 0s - loss: 0.9670 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 90/300\n",
            "1/1 - 0s - loss: 0.9662 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 91/300\n",
            "1/1 - 0s - loss: 0.9654 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 92/300\n",
            "1/1 - 0s - loss: 0.9646 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 93/300\n",
            "1/1 - 0s - loss: 0.9638 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 94/300\n",
            "1/1 - 0s - loss: 0.9630 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 95/300\n",
            "1/1 - 0s - loss: 0.9622 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 96/300\n",
            "1/1 - 0s - loss: 0.9614 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 97/300\n",
            "1/1 - 0s - loss: 0.9606 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 98/300\n",
            "1/1 - 0s - loss: 0.9599 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 99/300\n",
            "1/1 - 0s - loss: 0.9591 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 100/300\n",
            "1/1 - 0s - loss: 0.9583 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 101/300\n",
            "1/1 - 0s - loss: 0.9575 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 102/300\n",
            "1/1 - 0s - loss: 0.9567 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 103/300\n",
            "1/1 - 0s - loss: 0.9559 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 104/300\n",
            "1/1 - 0s - loss: 0.9551 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 105/300\n",
            "1/1 - 0s - loss: 0.9543 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 106/300\n",
            "1/1 - 0s - loss: 0.9536 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 107/300\n",
            "1/1 - 0s - loss: 0.9528 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 108/300\n",
            "1/1 - 0s - loss: 0.9520 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 109/300\n",
            "1/1 - 0s - loss: 0.9512 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 110/300\n",
            "1/1 - 0s - loss: 0.9505 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 111/300\n",
            "1/1 - 0s - loss: 0.9497 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 112/300\n",
            "1/1 - 0s - loss: 0.9489 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 113/300\n",
            "1/1 - 0s - loss: 0.9481 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 114/300\n",
            "1/1 - 0s - loss: 0.9474 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 115/300\n",
            "1/1 - 0s - loss: 0.9466 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 116/300\n",
            "1/1 - 0s - loss: 0.9458 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 117/300\n",
            "1/1 - 0s - loss: 0.9451 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 118/300\n",
            "1/1 - 0s - loss: 0.9443 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 119/300\n",
            "1/1 - 0s - loss: 0.9436 - acc: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 120/300\n",
            "1/1 - 0s - loss: 0.9428 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 121/300\n",
            "1/1 - 0s - loss: 0.9420 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 122/300\n",
            "1/1 - 0s - loss: 0.9413 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 123/300\n",
            "1/1 - 0s - loss: 0.9405 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 124/300\n",
            "1/1 - 0s - loss: 0.9398 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 125/300\n",
            "1/1 - 0s - loss: 0.9390 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 126/300\n",
            "1/1 - 0s - loss: 0.9383 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 127/300\n",
            "1/1 - 0s - loss: 0.9375 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 128/300\n",
            "1/1 - 0s - loss: 0.9368 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 129/300\n",
            "1/1 - 0s - loss: 0.9360 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 130/300\n",
            "1/1 - 0s - loss: 0.9353 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 131/300\n",
            "1/1 - 0s - loss: 0.9345 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 132/300\n",
            "1/1 - 0s - loss: 0.9338 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 133/300\n",
            "1/1 - 0s - loss: 0.9331 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 134/300\n",
            "1/1 - 0s - loss: 0.9323 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 135/300\n",
            "1/1 - 0s - loss: 0.9316 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 136/300\n",
            "1/1 - 0s - loss: 0.9308 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 137/300\n",
            "1/1 - 0s - loss: 0.9301 - acc: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 138/300\n",
            "1/1 - 0s - loss: 0.9294 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 139/300\n",
            "1/1 - 0s - loss: 0.9286 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 140/300\n",
            "1/1 - 0s - loss: 0.9279 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 141/300\n",
            "1/1 - 0s - loss: 0.9272 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 142/300\n",
            "1/1 - 0s - loss: 0.9264 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 143/300\n",
            "1/1 - 0s - loss: 0.9257 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 144/300\n",
            "1/1 - 0s - loss: 0.9250 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 145/300\n",
            "1/1 - 0s - loss: 0.9243 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 146/300\n",
            "1/1 - 0s - loss: 0.9235 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 147/300\n",
            "1/1 - 0s - loss: 0.9228 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 148/300\n",
            "1/1 - 0s - loss: 0.9221 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 149/300\n",
            "1/1 - 0s - loss: 0.9214 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 150/300\n",
            "1/1 - 0s - loss: 0.9207 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 151/300\n",
            "1/1 - 0s - loss: 0.9200 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 152/300\n",
            "1/1 - 0s - loss: 0.9192 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 153/300\n",
            "1/1 - 0s - loss: 0.9185 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 154/300\n",
            "1/1 - 0s - loss: 0.9178 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 155/300\n",
            "1/1 - 0s - loss: 0.9171 - acc: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 156/300\n",
            "1/1 - 0s - loss: 0.9164 - acc: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 157/300\n",
            "1/1 - 0s - loss: 0.9157 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 158/300\n",
            "1/1 - 0s - loss: 0.9150 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 159/300\n",
            "1/1 - 0s - loss: 0.9143 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 160/300\n",
            "1/1 - 0s - loss: 0.9136 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 161/300\n",
            "1/1 - 0s - loss: 0.9129 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 162/300\n",
            "1/1 - 0s - loss: 0.9122 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 163/300\n",
            "1/1 - 0s - loss: 0.9115 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 164/300\n",
            "1/1 - 0s - loss: 0.9108 - acc: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 165/300\n",
            "1/1 - 0s - loss: 0.9101 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 166/300\n",
            "1/1 - 0s - loss: 0.9094 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 167/300\n",
            "1/1 - 0s - loss: 0.9087 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 168/300\n",
            "1/1 - 0s - loss: 0.9080 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 169/300\n",
            "1/1 - 0s - loss: 0.9073 - acc: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 170/300\n",
            "1/1 - 0s - loss: 0.9066 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 171/300\n",
            "1/1 - 0s - loss: 0.9059 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 172/300\n",
            "1/1 - 0s - loss: 0.9052 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 173/300\n",
            "1/1 - 0s - loss: 0.9045 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 174/300\n",
            "1/1 - 0s - loss: 0.9038 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 175/300\n",
            "1/1 - 0s - loss: 0.9032 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 176/300\n",
            "1/1 - 0s - loss: 0.9025 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 177/300\n",
            "1/1 - 0s - loss: 0.9018 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 178/300\n",
            "1/1 - 0s - loss: 0.9011 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 179/300\n",
            "1/1 - 0s - loss: 0.9004 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 180/300\n",
            "1/1 - 0s - loss: 0.8998 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 181/300\n",
            "1/1 - 0s - loss: 0.8991 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 182/300\n",
            "1/1 - 0s - loss: 0.8984 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 183/300\n",
            "1/1 - 0s - loss: 0.8977 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 184/300\n",
            "1/1 - 0s - loss: 0.8971 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 185/300\n",
            "1/1 - 0s - loss: 0.8964 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 186/300\n",
            "1/1 - 0s - loss: 0.8957 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 187/300\n",
            "1/1 - 0s - loss: 0.8950 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 188/300\n",
            "1/1 - 0s - loss: 0.8944 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 189/300\n",
            "1/1 - 0s - loss: 0.8937 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 190/300\n",
            "1/1 - 0s - loss: 0.8930 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 191/300\n",
            "1/1 - 0s - loss: 0.8924 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 192/300\n",
            "1/1 - 0s - loss: 0.8917 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 193/300\n",
            "1/1 - 0s - loss: 0.8910 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 194/300\n",
            "1/1 - 0s - loss: 0.8904 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 195/300\n",
            "1/1 - 0s - loss: 0.8897 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 196/300\n",
            "1/1 - 0s - loss: 0.8891 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 197/300\n",
            "1/1 - 0s - loss: 0.8884 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 198/300\n",
            "1/1 - 0s - loss: 0.8878 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 199/300\n",
            "1/1 - 0s - loss: 0.8871 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 200/300\n",
            "1/1 - 0s - loss: 0.8864 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 201/300\n",
            "1/1 - 0s - loss: 0.8858 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 202/300\n",
            "1/1 - 0s - loss: 0.8851 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 203/300\n",
            "1/1 - 0s - loss: 0.8845 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 204/300\n",
            "1/1 - 0s - loss: 0.8838 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 205/300\n",
            "1/1 - 0s - loss: 0.8832 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 206/300\n",
            "1/1 - 0s - loss: 0.8825 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 207/300\n",
            "1/1 - 0s - loss: 0.8819 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 208/300\n",
            "1/1 - 0s - loss: 0.8813 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 209/300\n",
            "1/1 - 0s - loss: 0.8806 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 210/300\n",
            "1/1 - 0s - loss: 0.8800 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 211/300\n",
            "1/1 - 0s - loss: 0.8793 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 212/300\n",
            "1/1 - 0s - loss: 0.8787 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 213/300\n",
            "1/1 - 0s - loss: 0.8780 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 214/300\n",
            "1/1 - 0s - loss: 0.8774 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 215/300\n",
            "1/1 - 0s - loss: 0.8768 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 216/300\n",
            "1/1 - 0s - loss: 0.8761 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 217/300\n",
            "1/1 - 0s - loss: 0.8755 - acc: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 218/300\n",
            "1/1 - 0s - loss: 0.8749 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 219/300\n",
            "1/1 - 0s - loss: 0.8742 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 220/300\n",
            "1/1 - 0s - loss: 0.8736 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 221/300\n",
            "1/1 - 0s - loss: 0.8730 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 222/300\n",
            "1/1 - 0s - loss: 0.8724 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 223/300\n",
            "1/1 - 0s - loss: 0.8717 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 224/300\n",
            "1/1 - 0s - loss: 0.8711 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 225/300\n",
            "1/1 - 0s - loss: 0.8705 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 226/300\n",
            "1/1 - 0s - loss: 0.8699 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 227/300\n",
            "1/1 - 0s - loss: 0.8692 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 228/300\n",
            "1/1 - 0s - loss: 0.8686 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 229/300\n",
            "1/1 - 0s - loss: 0.8680 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 230/300\n",
            "1/1 - 0s - loss: 0.8674 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 231/300\n",
            "1/1 - 0s - loss: 0.8667 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 232/300\n",
            "1/1 - 0s - loss: 0.8661 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 233/300\n",
            "1/1 - 0s - loss: 0.8655 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 234/300\n",
            "1/1 - 0s - loss: 0.8649 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 235/300\n",
            "1/1 - 0s - loss: 0.8643 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 236/300\n",
            "1/1 - 0s - loss: 0.8637 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 237/300\n",
            "1/1 - 0s - loss: 0.8631 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 238/300\n",
            "1/1 - 0s - loss: 0.8625 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 239/300\n",
            "1/1 - 0s - loss: 0.8618 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 240/300\n",
            "1/1 - 0s - loss: 0.8612 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 241/300\n",
            "1/1 - 0s - loss: 0.8606 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 242/300\n",
            "1/1 - 0s - loss: 0.8600 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 243/300\n",
            "1/1 - 0s - loss: 0.8594 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 244/300\n",
            "1/1 - 0s - loss: 0.8588 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 245/300\n",
            "1/1 - 0s - loss: 0.8582 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 246/300\n",
            "1/1 - 0s - loss: 0.8576 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 247/300\n",
            "1/1 - 0s - loss: 0.8570 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 248/300\n",
            "1/1 - 0s - loss: 0.8564 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 249/300\n",
            "1/1 - 0s - loss: 0.8558 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 250/300\n",
            "1/1 - 0s - loss: 0.8552 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 251/300\n",
            "1/1 - 0s - loss: 0.8546 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 252/300\n",
            "1/1 - 0s - loss: 0.8540 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 253/300\n",
            "1/1 - 0s - loss: 0.8534 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 254/300\n",
            "1/1 - 0s - loss: 0.8528 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 255/300\n",
            "1/1 - 0s - loss: 0.8522 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 256/300\n",
            "1/1 - 0s - loss: 0.8516 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 257/300\n",
            "1/1 - 0s - loss: 0.8511 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 258/300\n",
            "1/1 - 0s - loss: 0.8505 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 259/300\n",
            "1/1 - 0s - loss: 0.8499 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 260/300\n",
            "1/1 - 0s - loss: 0.8493 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 261/300\n",
            "1/1 - 0s - loss: 0.8487 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 262/300\n",
            "1/1 - 0s - loss: 0.8481 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 263/300\n",
            "1/1 - 0s - loss: 0.8475 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 264/300\n",
            "1/1 - 0s - loss: 0.8469 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 265/300\n",
            "1/1 - 0s - loss: 0.8464 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 266/300\n",
            "1/1 - 0s - loss: 0.8458 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 267/300\n",
            "1/1 - 0s - loss: 0.8452 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 268/300\n",
            "1/1 - 0s - loss: 0.8446 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 269/300\n",
            "1/1 - 0s - loss: 0.8440 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 270/300\n",
            "1/1 - 0s - loss: 0.8435 - acc: 0.5000 - 7ms/epoch - 7ms/step\n",
            "Epoch 271/300\n",
            "1/1 - 0s - loss: 0.8429 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 272/300\n",
            "1/1 - 0s - loss: 0.8423 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 273/300\n",
            "1/1 - 0s - loss: 0.8417 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 274/300\n",
            "1/1 - 0s - loss: 0.8412 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 275/300\n",
            "1/1 - 0s - loss: 0.8406 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 276/300\n",
            "1/1 - 0s - loss: 0.8400 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 277/300\n",
            "1/1 - 0s - loss: 0.8395 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 278/300\n",
            "1/1 - 0s - loss: 0.8389 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 279/300\n",
            "1/1 - 0s - loss: 0.8383 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 280/300\n",
            "1/1 - 0s - loss: 0.8378 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 281/300\n",
            "1/1 - 0s - loss: 0.8372 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 282/300\n",
            "1/1 - 0s - loss: 0.8366 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 283/300\n",
            "1/1 - 0s - loss: 0.8361 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 284/300\n",
            "1/1 - 0s - loss: 0.8355 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 285/300\n",
            "1/1 - 0s - loss: 0.8349 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 286/300\n",
            "1/1 - 0s - loss: 0.8344 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 287/300\n",
            "1/1 - 0s - loss: 0.8338 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 288/300\n",
            "1/1 - 0s - loss: 0.8333 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 289/300\n",
            "1/1 - 0s - loss: 0.8327 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 290/300\n",
            "1/1 - 0s - loss: 0.8321 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 291/300\n",
            "1/1 - 0s - loss: 0.8316 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 292/300\n",
            "1/1 - 0s - loss: 0.8310 - acc: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 293/300\n",
            "1/1 - 0s - loss: 0.8305 - acc: 0.5000 - 8ms/epoch - 8ms/step\n",
            "Epoch 294/300\n",
            "1/1 - 0s - loss: 0.8299 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 295/300\n",
            "1/1 - 0s - loss: 0.8294 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 296/300\n",
            "1/1 - 0s - loss: 0.8288 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 297/300\n",
            "1/1 - 0s - loss: 0.8283 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 298/300\n",
            "1/1 - 0s - loss: 0.8277 - acc: 0.6667 - 9ms/epoch - 9ms/step\n",
            "Epoch 299/300\n",
            "1/1 - 0s - loss: 0.8272 - acc: 0.6667 - 8ms/epoch - 8ms/step\n",
            "Epoch 300/300\n",
            "1/1 - 0s - loss: 0.8266 - acc: 0.6667 - 8ms/epoch - 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model.predict(x, verbose=0)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3af3f36-d7cc-4974-c137-e351c71b89f2",
        "id": "b6qw8QPgTNKm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2268167  0.4383908  0.33479244]\n",
            " [0.3553608  0.28212598 0.3625132 ]\n",
            " [0.3909516  0.4546661  0.15438233]\n",
            " [0.5712271  0.27287617 0.15589681]\n",
            " [0.602832   0.35613146 0.04103645]\n",
            " [0.7753692  0.1881523  0.0364784 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_arg = np.argmax(p, axis=1)\n",
        "p_arg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d36b8b0-0e07-43ce-d2f2-96eadb84c0c2",
        "id": "Ctdm7K8uTNKn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d3b4dd-5714-4f19-fdb4-f103034d8b37",
        "id": "VfPPH_qkTNKn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 2, 1, 1, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.mean(p_arg == y)\n",
        "print('acc: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649725b6-a7d6-4fb1-a8e0-38460eb4831a",
        "id": "HSanaXiyTNKn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:  0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_4_1_iris.py"
      ],
      "metadata": {
        "id": "HeHnolOeXFk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing, model_selection\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KLRz61m7IA7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/iris.csv\")"
      ],
      "metadata": {
        "id": "4fJ5AzF2SO5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bznMmHWSYKLd",
        "outputId": "ea7e50d7-d88a-44f5-f116-77b142ccbb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal.length  sepal.width  petal.length  petal.width variety\n",
              "0           5.1          3.5           1.4          0.2  Setosa\n",
              "1           4.9          3.0           1.4          0.2  Setosa\n",
              "2           4.7          3.2           1.3          0.2  Setosa\n",
              "3           4.6          3.1           1.5          0.2  Setosa\n",
              "4           5.0          3.6           1.4          0.2  Setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71dc5db2-9944-4a38-a8fe-c82d2eeeb78a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71dc5db2-9944-4a38-a8fe-c82d2eeeb78a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71dc5db2-9944-4a38-a8fe-c82d2eeeb78a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71dc5db2-9944-4a38-a8fe-c82d2eeeb78a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SvS1PLQadCm",
        "outputId": "ff796061-1dd2-49c0-cc80-3bb1f5a43694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal.length  150 non-null    float64\n",
            " 1   sepal.width   150 non-null    float64\n",
            " 2   petal.length  150 non-null    float64\n",
            " 3   petal.width   150 non-null    float64\n",
            " 4   variety       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['variety'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGXhnZ8iYK9I",
        "outputId": "f2da4c88-d60f-4550-f09f-f93613b457c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.values[:, :-1]\n",
        "x = np.float32(x)\n",
        "y = df.values[:, -1]"
      ],
      "metadata": {
        "id": "unnL5aJpaODO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = preprocessing.LabelBinarizer()\n",
        "y = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "_oS2ZRfHIubv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x: ', x.dtype,\n",
        "        '\\ny: ',  y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP8n3CR9IeDv",
        "outputId": "4e2c89d4-626a-4bf1-f2bb-e070dcb17329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  float32 \n",
            "y:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz \n",
        "앞에서 읽어온 데이터에 대해 80%로 학습하고\n",
        "\n",
        " 28%에 대해 정확도를 구하세요"
      ],
      "metadata": {
        "id": "NWYutju7JNQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9HPsaK4Jojs",
        "outputId": "486fccc7-b0e5-4400-b84a-8df92c809fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4) (150, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, train_size=0.75, shuffle=True) "
      ],
      "metadata": {
        "id": "Ub_izfjlMmTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_regression_onehot(x, y):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=[4]))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    model.summary()    \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
        "                loss=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics='acc')\n",
        "\n",
        "    model.fit(x, y, epochs=300, verbose=2)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lyqrkgjJas34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = softmax_regression_onehot(x_train, y_train)"
      ],
      "metadata": {
        "id": "jor2QUOMJw12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz6IYjw7KjAz",
        "outputId": "02240c76-f6e8-4ed8-aec5-c27ae295c60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3053 - acc: 0.9474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3052500784397125, 0.9473684430122375]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model.predict(x_test)\n",
        "p_arg = np.argmax(p, axis=1)\n",
        "y_arg = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONSwN3P7Lw_3",
        "outputId": "9bb3df4f-12e1-4a1a-b1a8-ebcb85232eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.mean(p_arg == y_arg)"
      ],
      "metadata": {
        "id": "4MVdnIYnNiOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-khva62DNr31",
        "outputId": "8fd81c00-499d-4e11-ede0-e73cdf03977f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL_4_1_iris_sparse.py"
      ],
      "metadata": {
        "id": "ySAruNLwN-q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing, model_selection\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "BdYzQY7AObMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/디지털오픈랩 딥러닝 교육/data/iris.csv\")"
      ],
      "metadata": {
        "id": "GsS6VXRTObMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "eecc24b9-4f0a-4e45-ece1-5158a15d5454",
        "id": "Zk-tGFmzObMz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal.length  sepal.width  petal.length  petal.width variety\n",
              "0           5.1          3.5           1.4          0.2  Setosa\n",
              "1           4.9          3.0           1.4          0.2  Setosa\n",
              "2           4.7          3.2           1.3          0.2  Setosa\n",
              "3           4.6          3.1           1.5          0.2  Setosa\n",
              "4           5.0          3.6           1.4          0.2  Setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6422f6a7-2a3e-4c33-959f-235bc4de8f4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6422f6a7-2a3e-4c33-959f-235bc4de8f4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6422f6a7-2a3e-4c33-959f-235bc4de8f4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6422f6a7-2a3e-4c33-959f-235bc4de8f4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6800a47c-c36f-4350-fdad-801adc3a4764",
        "id": "IqOvO_5HObM0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal.length  150 non-null    float64\n",
            " 1   sepal.width   150 non-null    float64\n",
            " 2   petal.length  150 non-null    float64\n",
            " 3   petal.width   150 non-null    float64\n",
            " 4   variety       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['variety'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7658c9-d1de-4760-e68f-d4a47101d349",
        "id": "nxB0fgovObM0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.values[:, :-1]\n",
        "x = np.float32(x)\n",
        "y = df.values[:, -1]"
      ],
      "metadata": {
        "id": "JeUy0-krObM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = preprocessing.LabelEncoder()\n",
        "y = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "Xh68lEghObM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x: ', x.dtype,\n",
        "        '\\ny: ',  y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca4d8fc-6fa0-4be3-dc65-be2f354a126e",
        "id": "TSwZV8eeObM1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  float32 \n",
            "y:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz \n",
        "앞에서 읽어온 데이터에 대해 80%로 학습하고\n",
        "\n",
        " 28%에 대해 정확도를 구하세요"
      ],
      "metadata": {
        "id": "qfzVotzuObM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75bac385-f339-44b1-fb8a-6234e89c96fb",
        "id": "ab3T40SwObM1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, train_size=0.75, shuffle=True) "
      ],
      "metadata": {
        "id": "NgjJLVw-ObM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_regression_onehot(x, y):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=[4]))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    model.summary()    \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics='acc')\n",
        "\n",
        "    model.fit(x, y, epochs=300, verbose=2)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "hf51HuabObM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = softmax_regression_onehot(x_train, y_train)"
      ],
      "metadata": {
        "id": "4InrBtYxObM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c54376f-d086-4f8c-f34c-1552a8d4ce92",
        "id": "PXaT7TiuObM3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f69edd4ee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2789 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27888208627700806, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model.predict(x_test)\n",
        "p_arg = np.argmax(p, axis=1)\n",
        "# y_arg = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d269b4-dca1-4160-e474-d0362411aed0",
        "id": "TL2neXOoObM3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.mean(p_arg == y_test)\n",
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDa5BrITObM3",
        "outputId": "a0cd9c26-c1df-40c1-ce55-dac2bd7cb5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Z_20EIxPRuB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}